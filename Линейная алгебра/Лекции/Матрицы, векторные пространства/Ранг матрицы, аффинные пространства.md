
## I. Ранг матрицы и его свойства

**Теорема о совпадении рангов**

Размерность линейной оболочки системы столбцов некоторой матрицы совпадает с размерностью линейной оболочки системы строк этой же матрицы.

> _Простое объяснение:_ Если мы рассматриваем матрицу, то количество линейно независимых строк (строчный ранг) всегда равно количеству линейно независимых столбцов (столбцовый ранг).

Эта общая размерность называется **рангом матрицы**. Ранг можно найти, приводя матрицу к ступенчатому виду (по строкам или столбцам), при этом количество ненулевых строк/столбцов останется одинаковым.

**Доказательство с использованием гомоморфизмов и дуальности:**

1. Рассмотрим матрицу $A$ как матрицу гомоморфизма из пространства $U$ в пространство $V$. Размерность образа этого гомоморфизма ($\dim(\text{Im}(A))$) равна размерности линейной оболочки столбцов. _Это логично, поскольку столбцы содержат координаты образов базисных векторов, а образ гомоморфизма есть их линейная оболочка_.
2. Рассмотрим сопряжённый гомоморфизм $A$, действующий из $V$ в $U$. Матрица $A$ в сопряжённых базисах является транспонированной матрицей $A^T$.
3. Размерность образа сопряжённого гомоморфизма ($\dim(\text{Im}(A^*))$) равна размерности системы столбцов $A^T$, что совпадает с размерностью системы строк исходной матрицы $A$.
4. С другой стороны, размерность образа сопряжённого гомоморфизма $\dim(\text{Im}(A^*))$ равна размерности аннулятора ядра исходного гомоморфизма.
5. По теореме о размерности аннулятора (для конечномерных пространств): $$\dim(\text{Im}(A^*)) = \dim(\text{Ann}(\text{Ker}(A))) = \dim(U) - \dim(\text{Ker}(A)) \text{.}$$
6. По теореме о сумме размерности ядра и образа: $$\dim(U) - \dim(\text{Ker}(A)) = \dim(\text{Im}(A)) \text{.}$$
7. Следовательно, $\dim(\text{Im}(A^*)) = \dim(\text{Im}(A))$, что доказывает совпадение строчного и столбцового рангов.

---

## II. Критерий совместности СЛАУ

**Теорема Кронекера–Капелли**

Система линейных алгебраических уравнений (СЛАУ) $Ax = B$ совместно (то есть имеет хотя бы одно решение) тогда и только тогда, когда ранг матрицы коэффициентов (основной матрицы $A$) совпадает с рангом расширенной матрицы.

> _Интуитивное понимание:_ СЛАУ имеет решение, если вектор свободных членов $B$ можно составить из столбцов $A$. Если вектор $B$ уже является линейной комбинацией столбцов $A$, то он не увеличит «размах» (линейную оболочку) системы столбцов.

**Доказательство:**

1. **Если СЛАУ совместно** ($\implies$): Существует набор коэффициентов $\lambda_1, \dots, \lambda_N$ такой, что $A_1 \lambda_1 + \dots + A_N \lambda_N = B$ (где $A_i$ — столбцы матрицы $A$). Это означает, что $B$ является линейной комбинацией столбцов $A$. Добавление линейной комбинации к системе векторов не меняет размерность их линейной оболочки. Так как ранги — это размерности линейных оболочек столбцов, то ранг $A$ совпадает с рангом расширенной матрицы.
2. **Если ранги совпадают** ($\impliedby$): Равенство рангов означает равенство размерностей линейных оболочек столбцов. Если мы добавили вектор $B$ к системе столбцов $A$, и размерность не поменялась, это означает, что вектор $B$ уже лежал в линейной оболочке столбцов $A$. _Если бы $B$ был линейно независим с $A$, размерность бы увеличилась_. Следовательно, $B$ — линейная комбинация столбцов $A$, и существует набор коэффициентов (решение), что гарантирует совместность СЛАУ.

---

## III. Точные последовательности гомоморфизмов

**Определение точной последовательности**

Последовательность гомоморфизмов конечномерных пространств, например, $\dots \to U \xrightarrow{A} V \xrightarrow{B} W \to \dots$, называется **точной в члене $V$**, если образ гомоморфизма $A$ совпадает с ядром гомоморфизма $B$: $\text{Im}(A) = \text{Ker}(B)$.

> _Простое объяснение:_ Все, что попадает в пространство $V$ из $U$ под действием $A$ (образ $A$), является именно тем, что будет обнулено гомоморфизмом $B$ при переходе в $W$ (ядро $B$).

**Примеры коротких точных последовательностей (из трёх членов):**

1. **Эпиморфизм (отображение «на»):** $$U \xrightarrow{A} V \to 0$$ Если последовательность точна, то образ $A$ равен ядру гомоморфизма, действующего из $V$ в $0$. Ядром этого гомоморфизма является все пространство $V$. Следовательно, $\text{Im}(A) = V$, и гомоморфизм $A$ является отображением на $V$ (эпиморфизмом).
2. **Мономорфизм (инъективное отображение):** $$0 \to U \xrightarrow{B} V$$ Если последовательность точна, то образ гомоморфизма из $0$ в $U$ (который является только нулевым подпространством) совпадает с ядром $B$. Следовательно, $\text{Ker}(B) = {0}$ (тривиальное ядро), и гомоморфизм $B$ является мономорфизмом.

**Конструкция точной последовательности (пятичленная):**

С использованием ядра ($\text{Ker}(A)$) и коядра (фактор-пространства по образу гомоморфизма, $\text{Coker}(A) = V/\text{Im}(A)$) можно построить длинную точную последовательность, связывающую эти понятия с самим гомоморфизмом: $$0 \to \text{Ker}(A) \to U \xrightarrow{A} V \to V/\text{Im}(A) \to 0 \text{.}$$

---

## IV. Точность и сопряжённые объекты (Дуальность)

**Теорема о сохранении точности**

При переходе к сопряжённым пространствам и сопряжённым гомоморфизмам (дуальным объектам) точность последовательности сохраняется, но направление стрелок меняется на обратное.

Если последовательность $U \xrightarrow{A} V \xrightarrow{B} W$ точна, то сопряжённая последовательность $W^* \xrightarrow{B^*} V^* \xrightarrow{A^*} U^*$ также точна.

**Доказательство сохранения точности в $V^*$ (ключевые шаги):**

Нам необходимо доказать, что $\text{Im}(B^*) = \text{Ker}(A^*)$.

1. __Включение ($\text{Im}(B) \subseteq \text{Ker}(A)$):**
    
    - Пусть $\eta$ лежит в образе $B$. Это значит, что $\eta = B(\omega)$ для некоторой линейной функции $\omega \in W^*$.
    - Чтобы доказать, что $\eta$ лежит в ядре $A$, нужно проверить, что $A(\eta)$ — нулевая функция.
    - Проверим действие функции $A^*(\eta)$ на произвольный вектор $u \in U$: $$\langle A^*(\eta), u \rangle = \langle \eta, A(u) \rangle \text{ (по определению } A^*) \text{.}$$
    - Подставим $\eta = B^*(\omega)$: $$\langle B^*(\omega), A(u) \rangle = \langle \omega, B(A(u)) \rangle \text{ (по определению } B^*) \text{.}$$
    - Так как исходная последовательность точна, $\text{Im}(A) = \text{Ker}(B)$. Вектор $A(u)$ лежит в образе $A$, следовательно, он лежит в ядре $B$.
    - Поэтому $B(A(u)) = 0$.
    - $\langle \omega, 0 \rangle = 0$.
    - Так как $A^*(\eta)$ переводит произвольный вектор $u$ в ноль, $A^*(\eta)$ — нулевая функция. Включение доказано.
2. **Равенство размерностей (для конечномерных пространств):**
    
    - Мы знаем, что $\dim(\text{Ker}(A^*)) = \dim(\text{Ann}(\text{Im}(A)))$.
    - По теореме о размерности аннулятора: $\dim(\text{Ann}(\text{Im}(A))) = \dim(V) - \dim(\text{Im}(A))$.
    - Так как $\text{Im}(A) = \text{Ker}(B)$ (точность исходной последовательности), то $\dim(\text{Ker}(A^*)) = \dim(V) - \dim(\text{Ker}(B))$.
    - По теореме о размерности ядра и образа для $B$: $\dim(V) - \dim(\text{Ker}(B)) = \dim(\text{Im}(B))$.
    - Таким образом, $\dim(\text{Ker}(A^*)) = \dim(\text{Im}(B))$.
    - В конечномерных пространствах $\dim(\text{Im}(B^*)) = \dim(\text{Im}(B))$ (следствие теоремы о ранге).
    - Так как $\text{Im}(B^*)$ является подпространством $\text{Ker}(A^*)$ и их размерности совпадают, они равны: $\text{Im}(B^*) = \text{Ker}(A^*)$.

---

## V. Аффинные пространства

**Аффинное пространство (S)** вводится для аксиоматизации понятия **точек** и их связи с **векторами**.

Аффинное пространство $S$ ассоциировано с векторным пространством $V$ над полем $F$. Тройка $(S, V, +)$ часто называется аффинным пространством, подчеркивая неразрывную связь между точками $S$ и векторами $V$.

Аффинное пространство $S$ — это множество точек, для которого определена операция **сложения точки с вектором** (или параллельного переноса/сдвига): $S \times V \to S$.

$$A + v = B, \text{ где } A, B \in S, v \in V$$

**Аксиомы аффинного пространства:**

1. **Ассоциативность для векторов:** $(A + V) + U = A + (V + U)$.
2. **Действие нулевого вектора:** $A + 0 = A$. _Сдвиг на нулевой вектор не меняет положения точки_.
3. **Единственность соединяющего вектора:** Для любых двух точек $A$ и $B$ существует единственный вектор $V \in V$ такой, что $A + V = B$. Этот вектор обозначается $AB$. _Между двумя точками не может быть нескольких разных соединяющих векторов_.

**Следствия (Леммы):**

1. **Правило треугольника:** $AB + BC = AC$.
2. **Противоположный вектор:** Вектор $AB$ является противоположным вектору $BA$, т.е. $AB = -BA$.

**Размерность аффинного пространства**

Размерностью аффинного пространства $S$ называется размерность ассоциированного с ним векторного пространства $V$.

---

## VI. Координаты и замена репера

**Репер**

Для введения координат в аффинном пространстве необходим **репер** — выделенная точка $O$ (начало координат) и базис $E = (e_1, \dots, e_n)$ векторного пространства $V$.

Координатами точки $A \in S$ называются координаты единственного вектора $\vec{OA}$ в базисе $E$. Начало координат $O$ имеет нулевые координаты.

**Формула замены репера**

При переходе от старого репера $(O, E)$ к новому $(\tilde{O}, \tilde{E})$ меняется и начало координат, и базис.

Пусть $X$ — столбец старых координат точки $A$, $\tilde{X}$ — столбец новых координат $A$. Пусть $X_0$ — столбец старых координат нового начала координат $\tilde{O}$. Пусть $C$ — матрица перехода от старого базиса $E$ к новому базису $\tilde{E}$.

Вектор $\vec{OA}$ (который дает координаты $X$) можно представить как $\vec{OA} = \vec{O\tilde{O}} + \vec{\tilde{O}A}$.

В координатной форме это приводит к формуле, связывающей старые координаты с новыми: $$X = X_0 + C\tilde{X} \text{.}$$

> _Интуитивное объяснение:_ Координаты точки в старом репере получаются как сумма координат нового начала координат $X_0$ (перенос начала) и вектора $\vec{\tilde{O}A}$, выраженного через старый базис ($C\tilde{X}$ — преобразование координат вектора в связи со сменой базиса).

Обратная формула, выражающая новые координаты через старые: $$\tilde{X} = C^{-1}(X - X_0) \text{.}$$

Эта формула объединяет все частные случаи замены координат в аффинном пространстве, включая параллельный перенос начала координат (когда $C$ — единичная матрица) и чистую замену базиса (когда $X_0$ — нулевой вектор). Таким образом, аксиоматика аффинного пространства обобщает привычные понятия о точках, векторах и координатах, применимые к произвольному конечномерному пространству.