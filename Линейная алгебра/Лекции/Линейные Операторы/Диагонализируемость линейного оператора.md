
## 1. Обзор лекции

Лекция посвящена фундаментальной задаче линейной алгебры: когда линейный оператор допускает диагональное представление своей матрицы? Центральным объектом является понятие **диагонализируемого оператора** — оператора, в матрица которого в некотором базисе диагональна. Лекция строится по следующей логике: сначала вводится **спектральное разложение** диагонализируемого оператора через проекторы на собственные подпространства (спектральные проекторы), затем изучаются **препятствия к диагонализируемости** — отсутствие нужных корней характеристического многочлена в заданном поле и несовпадение алгебраической и геометрической кратностей собственных значений. Доказывается лемма о том, что геометрическая кратность не превосходит алгебраическую, и формулируется **критерий диагонализируемости**. Рассматриваются конкретные примеры: оператор дифференцирования на пространстве $\{\sin x, \cos x\}$ (недиагонализируем над $\mathbb{R}$, диагонализируем над $\mathbb{C}$ — пример комплексификации) и матрица сдвига последовательности Фибоначчи (диагонализируема над $\mathbb{R}$, даёт формулу Бине). В финале намечается программа следующей лекции: расширение понятия собственного вектора до корневого вектора для случая недиагонализируемых операторов.

---

## 2. Предварительные сведения

| Понятие | Краткое определение |
|---|---|
| Линейный оператор | Линейное отображение $A: V \to V$ векторного пространства в себя |
| Собственное значение | Скаляр $\lambda$ такой, что $Av = \lambda v$ для некоторого $v \neq 0$ |
| Собственный вектор | Ненулевой вектор $v$: $Av = \lambda v$ |
| Собственное подпространство | $V_\lambda = \ker(A - \lambda E) = \{v : Av = \lambda v\}$ |
| Характеристический многочлен | $\chi_A(t) = \det(tE - A)$ |
| Инвариантное подпространство | Подпространство $W \subset V$: $A(W) \subseteq W$ |
| Прямая сумма подпространств | $V = W_1 \oplus W_2 \oplus \cdots \oplus W_k$: единственность разложения |
| Проектор | Идемпотентный оператор $P^2 = P$ |
| Алгебраическое замыкание поля | Наименьшее расширение поля, где любой многочлен раскладывается на линейные множители |

---

## 3. Основное содержание

---

### 3.1. Мотивирующий пример: недостаток собственных векторов

Рассмотрим матрицу
$$A = \begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}.$$

**Характеристический многочлен:**
$$\chi_A(t) = \det\begin{pmatrix} t-1 & -1 \\ 0 & t-1 \end{pmatrix} = (t-1)^2.$$

Единственное собственное значение $\lambda = 1$ (алгебраическая кратность 2). Найдём собственные векторы:
$$(A - E)v = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = 0 \implies y = 0.$$

Следовательно, $V_1 = \mathrm{span}\{e_1\}$ — одномерное пространство. Собственных векторов **не хватает** для построения базиса $\mathbb{R}^2$. Оператор **не диагонализируем**.

**МОТИВАЦИЯ:** Этот пример показывает, что даже при единственном собственном значении оператор может не диагонализироваться. Надо понять, когда именно это происходит.

---

### 3.2. Спектральное разложение диагонализируемого оператора

#### Определение 3.1 (Диагонализируемый оператор)

Оператор $A: V \to V$ называется **диагонализируемым** над полем $\mathbb{F}$, если существует базис пространства $V$, в котором матрица оператора $A$ диагональна.

**МОТИВАЦИЯ:** Диагональная матрица — наипростейшая форма, с которой легко вычислять степени оператора, решать дифференциальные уравнения, анализировать поведение динамических систем.

**ИНТУИЦИЯ:** Диагонализируемость означает, что пространство "распадается" на независимые одномерные инвариантные подпространства — по одному для каждого собственного значения.

#### Теорема 3.1 (Спектральное разложение)

Пусть $A: V \to V$ — диагонализируемый оператор с попарно различными собственными значениями $\lambda_1, \ldots, \lambda_k$ (спектром). Тогда:

1. Пространство разлагается в прямую сумму собственных подпространств:
$$V = V_{\lambda_1} \oplus V_{\lambda_2} \oplus \cdots \oplus V_{\lambda_k}.$$

2. Существуют операторы $P_1, P_2, \ldots, P_k$ — **спектральные проекторы** на $V_{\lambda_i}$ вдоль $\bigoplus_{j \neq i} V_{\lambda_j}$ — такие, что:

   **(а)** $P_i^2 = P_i$ (идемпотентность),

   **(б)** $P_i P_j = 0$ при $i \neq j$ (ортогональность проекторов),

   **(в)** $\displaystyle\sum_{i=1}^k P_i = \mathrm{Id}$ (разложение единицы),

   **(г)** $\displaystyle A = \sum_{i=1}^k \lambda_i P_i$ (спектральное разложение оператора).

**Доказательство.**

[Идея:] Из прямой суммы получаем канонические проекторы. Убеждаемся, что линейная комбинация $\sum \lambda_i P_i$ действует на любой вектор так же, как $A$.

**Шаг 1.** Поскольку $A$ диагонализируем, существует базис $\{e_1, \ldots, e_n\}$ из собственных векторов:
$$Ae_j = \lambda_{i(j)} e_j,$$
где $i(j)$ — индекс собственного значения вектора $e_j$.

**Шаг 2.** Для каждого $i$ определим $P_i: V \to V_{\lambda_i}$ как проектор на $V_{\lambda_i}$ вдоль $\bigoplus_{j \neq i} V_{\lambda_j}$: если $v = \sum_{j} c_j e_j$, то
$$P_i(v) = \sum_{\{j\,:\,i(j) = i\}} c_j e_j.$$

**Шаг 3.** Проверим свойства:
- **Идемпотентность:** $P_i(P_i(v)) = P_i\!\left(\sum_{i(j)=i} c_j e_j\right) = \sum_{i(j)=i} c_j e_j = P_i(v)$. ✓
- **Ортогональность:** $P_i(P_j(v))$ для $i \neq j$: $P_j(v) \in V_{\lambda_j}$, а $P_i$ обнуляет $V_{\lambda_j}$. ✓
- **Полнота:** $\sum_i P_i(v) = \sum_i \sum_{i(j)=i} c_j e_j = \sum_j c_j e_j = v$. ✓

**Шаг 4.** Проверим спектральное разложение. Для произвольного $v \in V$:
$$\left(\sum_{i=1}^k \lambda_i P_i\right)(v) = \sum_{i=1}^k \lambda_i P_i(v) = \sum_{i=1}^k \lambda_i \sum_{i(j)=i} c_j e_j = \sum_j c_j \lambda_{i(j)} e_j.$$

С другой стороны:
$$A(v) = A\!\left(\sum_j c_j e_j\right) = \sum_j c_j A e_j = \sum_j c_j \lambda_{i(j)} e_j.$$

Оба выражения совпадают для любого $v$, следовательно:
$$A = \sum_{i=1}^k \lambda_i P_i. \quad \square$$

**ИНТУИЦИЯ:** Оператор $A$ «разбивается» на $k$ независимых операций: $P_i$ выделяет $\lambda_i$-компоненту вектора, а $\lambda_i$ масштабирует её. Это точный аналог спектрального разложения самосопряжённых матриц из матанализа.

#### Определение 3.2 (Спектр оператора)

**Спектром** оператора $A$ называется набор всех собственных значений $\lambda_1, \ldots, \lambda_k$ с учётом алгебраических кратностей, то есть совокупность всех корней характеристического многочлена $\chi_A(t)$ (в алгебраическом замыкании поля).

**Замечание 3.1.** Спектральные проекторы называются «спектральными» именно потому, что они конструируются по спектру оператора. Обозначение: $P_{\lambda_i}$ или $P_i$.

---

### 3.3. Инвариантные подпространства и характеристический многочлен

#### Лемма 3.1 (Делимость характеристического многочлена)

Пусть $W \subset V$ — инвариантное подпространство оператора $A$. Тогда характеристический многочлен сужения $\chi_{A|_W}(t)$ делит характеристический многочлен $\chi_A(t)$.

**Доказательство.**

[Идея:] Выберем базис, согласованный с $W$, и воспользуемся блочно-треугольным видом матрицы и мультипликативностью определителя.

**Шаг 1.** Пусть $\dim W = k$, $\dim V = n$. Выберем базис $\{e_1, \ldots, e_k\}$ пространства $W$ и дополним его до базиса $\{e_1, \ldots, e_k, e_{k+1}, \ldots, e_n\}$ пространства $V$.

**Шаг 2.** Поскольку $W$ инвариантно ($A(W) \subseteq W$), образы $Ae_1, \ldots, Ae_k$ принадлежат $W$. Поэтому в матрице оператора $A$ в этом базисе правый нижний блок «не влияет» на левые столбцы:
$$[A] = \begin{pmatrix} B & * \\ 0 & D \end{pmatrix},$$
где $B$ — матрица $k \times k$ сужения $A|_W$ в базисе $e_1, \ldots, e_k$, $D$ — матрица $(n-k) \times (n-k)$, $*$ — произвольный блок.

**Шаг 3.** Вычислим характеристический многочлен:
$$\chi_A(t) = \det(tE_n - A) = \det\begin{pmatrix} tE_k - B & -* \\ 0 & tE_{n-k} - D \end{pmatrix}.$$

По теореме о блочно-треугольном определителе (если в нижнем левом углу стоят нули):
$$\chi_A(t) = \det(tE_k - B) \cdot \det(tE_{n-k} - D) = \chi_{A|_W}(t) \cdot \det(tE_{n-k} - D).$$

**Шаг 4.** Следовательно, $\chi_{A|_W}(t) \mid \chi_A(t)$. $\square$

**МОТИВАЦИЯ:** Эта лемма — ключевой технический инструмент для сравнения алгебраической и геометрической кратностей.

---

### 3.4. Алгебраическая и геометрическая кратности

#### Определение 3.3 (Алгебраическая кратность)

**Алгебраической кратностью** собственного значения $\lambda$ оператора $A$ называется кратность $\lambda$ как корня характеристического многочлена $\chi_A(t)$. Обозначается $\mathrm{alg}(\lambda)$ или $a(\lambda)$.

#### Определение 3.4 (Геометрическая кратность)

**Геометрической кратностью** собственного значения $\lambda$ называется размерность соответствующего собственного подпространства:
$$\mathrm{geo}(\lambda) = \dim V_\lambda = \dim \ker(A - \lambda E).$$

**МОТИВАЦИЯ:** Алгебраическая кратность — это «сколько раз $\lambda$ является корнем», геометрическая — «сколько линейно независимых собственных векторов соответствует $\lambda$». Диагонализируемость требует, чтобы эти числа совпадали.

**ИНТУИЦИЯ:** Геометрическая кратность — это реальное число собственных векторов (размерность «собственного слоя»). Алгебраическая — формальная «мощность» корня. Если алгебраическая больше геометрической, значит, характеристический многочлен «обещает» больше векторов, чем реально есть: именно здесь и «прячутся» жордановы клетки.

#### Лемма 3.2 (Геометрическая кратность не превосходит алгебраическую)

Для любого собственного значения $\lambda$ оператора $A$:
$$\mathrm{geo}(\lambda) \leq \mathrm{alg}(\lambda).$$

**Доказательство.**

[Идея:] Собственное подпространство $V_\lambda$ инвариантно. По Лемме 3.1 характеристический многочлен сужения $A|_{V_\lambda}$ делит $\chi_A(t)$. Сужение — скалярный оператор $\lambda \cdot \mathrm{Id}$, его характеристический многочлен равен $(t - \lambda)^{\dim V_\lambda}$.

**Шаг 1.** Собственное подпространство $V_\lambda$ инвариантно: для любого $v \in V_\lambda$ выполнено $Av = \lambda v \in V_\lambda$. Это следует непосредственно из определения.

**Шаг 2.** Рассмотрим сужение $A|_{V_\lambda}: V_\lambda \to V_\lambda$. Поскольку $Av = \lambda v$ для всех $v \in V_\lambda$, это сужение является скалярным оператором $\lambda \cdot \mathrm{Id}_{V_\lambda}$.

**Шаг 3.** Матрица сужения в любом базисе $V_\lambda$ диагональна:
$$[A|_{V_\lambda}] = \lambda E_m, \quad m = \mathrm{geo}(\lambda).$$

Характеристический многочлен сужения:
$$\chi_{A|_{V_\lambda}}(t) = (t - \lambda)^m.$$

**Шаг 4.** По Лемме 3.1: $\chi_{A|_{V_\lambda}}(t) \mid \chi_A(t)$, то есть $(t - \lambda)^m \mid \chi_A(t)$.

**Шаг 5.** Следовательно, $\lambda$ является корнем $\chi_A(t)$ кратности не менее $m$:
$$\mathrm{alg}(\lambda) \geq m = \mathrm{geo}(\lambda). \quad \square$$

**ТИПИЧНЫЕ ОШИБКИ:**
- Путать направление неравенства: $\mathrm{geo} \leq \mathrm{alg}$, а не наоборот.
- Считать, что равенство всегда выполняется: матрица $\begin{pmatrix}1&1\\0&1\end{pmatrix}$ — контрпример: $\mathrm{alg}(1)=2$, $\mathrm{geo}(1)=1$.

#### Пример 3.1 (Оператор дифференцирования на пространстве многочленов)

Рассмотрим пространство $V = \mathbb{R}[x]_{\leq m}$ многочленов степени $\leq m$ с оператором $D = \frac{d}{dx}$.

В стандартном базисе $\{1, x, x^2, \ldots, x^m\}$ матрица $D$ верхнетреугольна:
$$[D] = \begin{pmatrix} 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & 2 & \cdots & 0 \\ \vdots & & \ddots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & m \\ 0 & 0 & 0 & \cdots & 0 \end{pmatrix}.$$

Характеристический многочлен: $\chi_D(t) = t^{m+1}$ (единственный корень $\lambda = 0$ кратности $m+1$).

Собственное пространство $V_0 = \ker D$ — это пространство констант, $\dim V_0 = 1$.

Следовательно:
$$\mathrm{alg}(0) = m+1, \quad \mathrm{geo}(0) = 1.$$

При $m \geq 1$ имеем $\mathrm{geo}(0) < \mathrm{alg}(0)$, и оператор **не диагонализируем**.

---

### 3.5. Препятствия к диагонализируемости

Из проведённого анализа вытекают два типа препятствий.

#### Препятствие I. Характеристический многочлен не раскладывается на линейные множители над $\mathbb{F}$

Если $\chi_A(t)$ имеет корни, не лежащие в поле $\mathbb{F}$ (например, вещественный оператор имеет комплексные собственные значения), то пространство $V$ не может быть разложено в прямую сумму собственных подпространств над $\mathbb{F}$.

Формально: если $\sum_{\lambda \in \mathbb{F}} \mathrm{alg}(\lambda) < n = \dim V$, то $\sum_\lambda \dim V_\lambda \leq \sum_\lambda \mathrm{alg}(\lambda) < n$, и базиса из собственных векторов нет.

**Это препятствие можно обойти:** перейти к алгебраическому замыканию (например, от $\mathbb{R}$ к $\mathbb{C}$).

#### Препятствие II. Алгебраическая кратность строго больше геометрической

Даже если все корни лежат в $\mathbb{F}$, но для некоторого $\lambda$:
$$\mathrm{geo}(\lambda) < \mathrm{alg}(\lambda),$$
то $\sum_\lambda \dim V_\lambda < n$, собственных векторов для базиса не хватает.

**Это препятствие непреодолимо** даже переходом к расширению поля — оно связано с внутренней структурой оператора (жордановой формой).

---

### 3.6. Критерий диагонализируемости

#### Теорема 3.2 (Критерий диагонализируемости)

Оператор $A: V \to V$ над полем $\mathbb{F}$ диагонализируем тогда и только тогда, когда выполнены оба условия:

**(1)** Характеристический многочлен $\chi_A(t)$ раскладывается на линейные множители над $\mathbb{F}$:
$$\chi_A(t) = (t - \lambda_1)^{a_1}(t - \lambda_2)^{a_2} \cdots (t - \lambda_k)^{a_k}, \quad \lambda_i \in \mathbb{F}.$$

**(2)** Для каждого собственного значения $\lambda_i$ геометрическая кратность равна алгебраической:
$$\mathrm{geo}(\lambda_i) = \mathrm{alg}(\lambda_i) \quad \forall i = 1, \ldots, k.$$

**Доказательство (необходимость).**

Если $A$ диагонализируем, то существует базис из собственных векторов. Тогда матрица диагональна, характеристический многочлен — произведение $(t - \lambda_i)$ — раскладывается на линейные множители над $\mathbb{F}$ (условие 1). При этом $\dim V_{\lambda_i}$ равно числу вхождений $\lambda_i$ на диагонали, то есть $\mathrm{alg}(\lambda_i)$ (условие 2).

**Доказательство (достаточность).**

[восстановлено] Пусть оба условия выполнены. Тогда:
$$\dim V = n = \sum_{i=1}^k \mathrm{alg}(\lambda_i) = \sum_{i=1}^k \mathrm{geo}(\lambda_i) = \sum_{i=1}^k \dim V_{\lambda_i}.$$

Покажем, что $V = V_{\lambda_1} \oplus \cdots \oplus V_{\lambda_k}$. Из стандартной теоремы о линейной независимости собственных подпространств: если $\lambda_i$ попарно различны, то $V_{\lambda_1} + \cdots + V_{\lambda_k}$ — прямая. Объединение базисов каждого $V_{\lambda_i}$ даёт базис $V$ из $\sum \dim V_{\lambda_i} = n$ векторов. Это и есть базис из собственных векторов, в котором матрица $A$ диагональна. $\square$ [/восстановлено]

**МОТИВАЦИЯ:** Критерий даёт алгоритм проверки диагонализируемости: (1) найти корни $\chi_A(t)$ и проверить, лежат ли они в $\mathbb{F}$; (2) для каждого корня проверить, совпадают ли кратности.

**ИНТУИЦИЯ:** Условие (2) — геометрически означает, что каждое собственное значение «порождает» ровно столько независимых собственных векторов, сколько обещает характеристический многочлен. Если «обещает» больше, чем реально есть — значит, часть векторов «обобщённые» (корневые), а не обычные собственные.

---

### 3.7. Пример: оператор дифференцирования на $\mathrm{span}_{\mathbb{R}}\{\sin x, \cos x\}$

Рассмотрим $V = \mathrm{span}_{\mathbb{R}}\{\sin x, \cos x\}$ — вещественное векторное пространство размерности 2, оператор $D = \frac{d}{dx}$.

**Матрица оператора** в базисе $e_1 = \sin x$, $e_2 = \cos x$:
$$De_1 = \cos x = 0 \cdot e_1 + 1 \cdot e_2, \quad De_2 = -\sin x = -1 \cdot e_1 + 0 \cdot e_2.$$
$$[D] = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}.$$

**Характеристический многочлен:**
$$\chi_D(t) = t^2 + 1.$$

Корни: $t = \pm i \notin \mathbb{R}$. Препятствие первого типа: оператор **не диагонализируем над $\mathbb{R}$**.

**Переход к $\mathbb{C}$ (комплексификация).**

Рассмотрим $V_{\mathbb{C}} = \mathrm{span}_{\mathbb{C}}\{\sin x, \cos x\} = \mathrm{span}_{\mathbb{C}}\{e^{ix}, e^{-ix}\}$ (так как $e^{ix} = \cos x + i\sin x$, $e^{-ix} = \cos x - i\sin x$).

Собственные значения: $\lambda_1 = i$, $\lambda_2 = -i$, каждое алгебраической кратности 1.

Собственные векторы:
- $D(e^{ix}) = ie^{ix}$, значит $e^{ix}$ — собственный вектор с $\lambda = i$.
- $D(e^{-ix}) = -ie^{-ix}$, значит $e^{-ix}$ — собственный вектор с $\lambda = -i$.

Поскольку оба собственных значения различны и лежат в $\mathbb{C}$, оператор **диагонализируем над $\mathbb{C}$**.

**Матрица перехода** от базиса $\{e^{ix}, e^{-ix}\}$ к базису $\{\sin x, \cos x\}$:
$$e^{ix} = \cos x + i\sin x = i \cdot \sin x + 1 \cdot \cos x,$$
$$e^{-ix} = \cos x - i\sin x = -i \cdot \sin x + 1 \cdot \cos x.$$

Таким образом:
$$C = \begin{pmatrix} i & -i \\ 1 & 1 \end{pmatrix}.$$

**Обратная матрица:**
$$\det C = i - (-i) = 2i, \quad C^{-1} = \frac{1}{2i}\begin{pmatrix} 1 & i \\ -1 & i \end{pmatrix} = \begin{pmatrix} \tfrac{1}{2i} & \tfrac{1}{2} \\ -\tfrac{1}{2i} & \tfrac{1}{2} \end{pmatrix}.$$

**Проверка:** $C^{-1}[D]C = \begin{pmatrix} i & 0 \\ 0 & -i \end{pmatrix}$ — диагональная матрица. ✓

**Характеристический многочлен** в новом базисе:
$$\chi(t) = (t - i)(t + i) = t^2 + 1. \quad \checkmark$$

**ЗАМЕЧАНИЕ:** Характеристический многочлен не зависит от выбора базиса.

---

### 3.8. Пример: последовательность Фибоначчи и диагонализируемость

#### Постановка задачи

Последовательность Фибоначчи задана рекуррентно:
$$f_0 = 0, \quad f_1 = 1, \quad f_n = f_{n-1} + f_{n-2}.$$

Требуется найти **замкнутую формулу** для $f_n$.

**МОТИВАЦИЯ:** Рекуррентные соотношения — классическая область применения диагонализируемости. Идея: переформулировать рекуррентность как действие матрицы, найти $A^n$ через диагонализацию.

#### Матричная форма

Введём вектор состояния $v_n = \begin{pmatrix} f_n \\ f_{n-1} \end{pmatrix}$. Тогда рекуррентность записывается как:
$$v_n = A v_{n-1}, \quad A = \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}.$$

Проверка:
$$\begin{pmatrix} f_n \\ f_{n-1} \end{pmatrix} = \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}\begin{pmatrix} f_{n-1} \\ f_{n-2} \end{pmatrix} = \begin{pmatrix} f_{n-1} + f_{n-2} \\ f_{n-1} \end{pmatrix}. \quad \checkmark$$

Следовательно: $v_n = A^n v_0 = A^n \begin{pmatrix} 0 \\ 1 \end{pmatrix}$
восстановлено: корректировка — $v_1 = \begin{pmatrix}1\\0\end{pmatrix}$, $v_n = A^{n-1} v_1$  /восстановлено
#### Диагонализация матрицы $A$

**Характеристический многочлен:**
$$\chi_A(t) = \det\begin{pmatrix} t-1 & -1 \\ -1 & t \end{pmatrix} = t(t-1) - 1 = t^2 - t - 1.$$

**Корни** (золотое сечение и его сопряжённое):
$$\lambda_{1,2} = \frac{1 \pm \sqrt{5}}{2}.$$

$\lambda_1 = \dfrac{1+\sqrt{5}}{2}$ (золотое сечение $\varphi \approx 1{,}618$), $\lambda_2 = \dfrac{1-\sqrt{5}}{2} \approx -0{,}618$.

Дискриминант $D = 5 > 0$, корни вещественные и **различные** $\Rightarrow$ оператор диагонализируем над $\mathbb{R}$.

#### Следствие о диагонализируемости при различных собственных значениях

[доказательство добавлено]

**Лемма.** Если $n$-мерный оператор имеет $n$ различных собственных значений $\lambda_1, \ldots, \lambda_n \in \mathbb{F}$, то он диагонализируем над $\mathbb{F}$.

**Доказательство.** Для каждого $\lambda_i$ геометрическая кратность $\mathrm{geo}(\lambda_i) \geq 1$ (собственный вектор существует) и $\mathrm{alg}(\lambda_i) \geq 1$. Поскольку все $\lambda_i$ различны и их $n$ штук, $\sum_i \mathrm{alg}(\lambda_i) = n$. Значит, каждое $\mathrm{alg}(\lambda_i) = 1$. По Лемме 3.2 $\mathrm{geo}(\lambda_i) \leq 1$, а значит $\mathrm{geo}(\lambda_i) = 1 = \mathrm{alg}(\lambda_i)$. Условия теоремы 3.2 выполнены. $\square$

#### Собственные векторы матрицы $A$

Для $\lambda_1$: решаем $(A - \lambda_1 E)x = 0$:
$$\begin{pmatrix} 1 - \lambda_1 & 1 \\ 1 & -\lambda_1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = 0.$$

Из первой строки: $(1 - \lambda_1)x + y = 0 \Rightarrow y = (\lambda_1 - 1)x$. Берём $x = 1$:
$$\xi_1 = \begin{pmatrix} 1 \\ \lambda_1 - 1 \end{pmatrix} = \begin{pmatrix} 1 \\ \lambda_2 \end{pmatrix}$$
восстановлено: поскольку $\lambda_1 - 1 = \frac{1+\sqrt5}{2}-1 = \frac{\sqrt5-1}{2} = \frac{1}{\lambda_1} = \lambda_2 + 1 - 1 = \lambda_2$... фактически $\lambda_1 - 1 = \lambda_1^{-1}$ по уравнению $\lambda^2 = \lambda + 1$ /восстановлено.

Аналогично $\xi_2 = \begin{pmatrix} 1 \\ \lambda_2 \end{pmatrix}$ для $\lambda_2$.

Матрица перехода:
$$C = \begin{pmatrix} 1 & 1 \\ \lambda_1 & \lambda_2 \end{pmatrix}, \quad C^{-1} = \frac{1}{\lambda_2 - \lambda_1}\begin{pmatrix} \lambda_2 & -1 \\ -\lambda_1 & 1 \end{pmatrix} = \frac{1}{-\sqrt{5}}\begin{pmatrix} \lambda_2 & -1 \\ -\lambda_1 & 1 \end{pmatrix}.$$

В собственном базисе: $\tilde{A} = C^{-1} A C = \begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix}$.

#### Вычисление $A^n$ и формула Бине

$$A^n = C \begin{pmatrix} \lambda_1^n & 0 \\ 0 & \lambda_2^n \end{pmatrix} C^{-1}.$$

Из этого перемножения (первая строка первого столбца результата, умноженного на начальные условия):

$$\boxed{f_n = \frac{\lambda_1^n - \lambda_2^n}{\lambda_1 - \lambda_2} = \frac{1}{\sqrt{5}}\left(\left(\frac{1+\sqrt{5}}{2}\right)^n - \left(\frac{1-\sqrt{5}}{2}\right)^n\right).}$$

Это знаменитая **формула Бине**.

**Проверка при $n=1$:** $f_1 = \frac{1}{\sqrt{5}}\left(\frac{1+\sqrt5}{2} - \frac{1-\sqrt5}{2}\right) = \frac{1}{\sqrt5} \cdot \sqrt{5} = 1$. ✓

**Проверка при $n=2$:** $f_2 = \frac{1}{\sqrt{5}}\left(\varphi^2 - \psi^2\right) = \frac{(\varphi+\psi)(\varphi-\psi)}{\sqrt{5}} = \frac{1 \cdot \sqrt{5}}{\sqrt{5}} = 1$. ✓

#### Обобщение: линейные рекуррентные соотношения

Общее линейное рекуррентное соотношение $k$-го порядка:
$$f_n = a_1 f_{n-1} + a_2 f_{n-2} + \cdots + a_k f_{n-k}$$
сводится к действию матрицы-компаньона $k \times k$:
$$A = \begin{pmatrix} a_1 & a_2 & \cdots & a_{k-1} & a_k \\ 1 & 0 & \cdots & 0 & 0 \\ 0 & 1 & \cdots & 0 & 0 \\ \vdots & & \ddots & & \vdots \\ 0 & 0 & \cdots & 1 & 0 \end{pmatrix}.$$

Характеристический многочлен $A$ совпадает с характеристическим многочленом рекуррентности $t^k - a_1 t^{k-1} - \cdots - a_k$. Если $A$ диагонализируем, задача решается через $A^n$. Если нет — нужна жорданова форма (тема следующих лекций).

---

## 4. Справочный лист

| Обозначение | Смысл |
|---|---|
| $\chi_A(t) = \det(tE - A)$ | Характеристический многочлен оператора $A$ |
| $V_\lambda = \ker(A - \lambda E)$ | Собственное подпространство |
| $\mathrm{alg}(\lambda)$ | Алгебраическая кратность: кратность $\lambda$ как корня $\chi_A$ |
| $\mathrm{geo}(\lambda) = \dim V_\lambda$ | Геометрическая кратность |
| $1 \leq \mathrm{geo}(\lambda) \leq \mathrm{alg}(\lambda)$ | Ключевое неравенство (Лемма 3.2) |

**Критерий диагонализируемости** ($A: V \to V$, $\dim V = n$, поле $\mathbb{F}$):
$$A \text{ диагонализируем} \iff \begin{cases} \chi_A(t) = (t-\lambda_1)^{a_1}\cdots(t-\lambda_k)^{a_k},\ \lambda_i \in \mathbb{F} \\ \mathrm{geo}(\lambda_i) = \mathrm{alg}(\lambda_i)\ \forall i \end{cases}$$

**Спектральное разложение** (если $A$ диагонализируем):
$$A = \sum_{i=1}^k \lambda_i P_i, \qquad P_i P_j = \delta_{ij} P_i, \qquad \sum_{i=1}^k P_i = \mathrm{Id}.$$

**Формула Бине:**
$$f_n = \frac{1}{\sqrt{5}}\left(\varphi^n - \psi^n\right), \quad \varphi = \frac{1+\sqrt{5}}{2},\ \psi = \frac{1-\sqrt{5}}{2}.$$

**Оператор дифференцирования на $\{\sin x, \cos x\}$:**
$$[D]_{\sin,\cos} = \begin{pmatrix}0&-1\\1&0\end{pmatrix}, \quad \chi_D(t) = t^2+1, \quad \text{собственные значения } \pm i \in \mathbb{C}.$$

---

## 5. Концептуальное резюме

Диагонализируемость — это свойство оператора «расщепляться» на независимые одномерные динамики, по одной на каждое собственное значение. Ключевое открытие лекции состоит в том, что диагонализируемость нарушается ровно по двум причинам: либо нужных собственных значений нет в рассматриваемом поле (первое препятствие, обходимое переходом к $\mathbb{C}$), либо для какого-то собственного значения «мало» собственных векторов относительно его алгебраической кратности (второе, глубокое препятствие, связанное с жордановой структурой). Спектральное разложение $A = \sum \lambda_i P_i$ — это точный операторный аналог разложения диагональной матрицы, выражающий действие оператора через проекции на собственные подпространства. Практическая мощь диагонализируемости наглядно видна на примере последовательности Фибоначчи: диагонализация матрицы сдвига немедленно даёт явную формулу Бине, а общий метод применим ко всем линейным рекуррентным соотношениям.

---

## 6. Связи с более широкой математикой

- **Жорданова нормальная форма:** когда диагонализируемость невозможна (геометрическая кратность < алгебраической), оператор приводится к жордановой форме — «почти диагональной» матрице с жордановыми клетками. Это тема следующих лекций.

- **Спектральная теорема:** для симметричных (самосопряжённых) операторов в евклидовом пространстве все собственные значения вещественны и оператор всегда диагонализируем (ортогонально). Это мощное обобщение критерия диагонализируемости.

- **Дифференциальные уравнения:** система $\dot{x} = Ax$ решается через $e^{At} = C e^{\Lambda t} C^{-1}$ для диагонализируемого $A$. При недиагонализируемом $A$ нужна жорданова форма для вычисления матричной экспоненты.

- **Комплексификация:** переход от вещественного пространства к комплексному — стандартный приём, позволяющий «разблокировать» первое препятствие диагонализируемости. Будет разобрана формально на следующей лекции.

- **Теория представлений:** диагонализируемость — частный случай полупростоты; неразложимые представления в точности соответствуют жордановым клеткам.

- **Численные методы:** алгоритмы нахождения собственных значений (метод QR, метод степеней) — это практические инструменты для диагонализации больших матриц в вычислительной математике.
