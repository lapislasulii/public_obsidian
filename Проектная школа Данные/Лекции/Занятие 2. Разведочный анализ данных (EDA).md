[[Презентация к занятию 2.pdf]]
## Конспект занятия №2: Разведочный анализ данных (EDA)

**Преподаватель:** Дмитрий Кротов, И.о. Team Lead аналитиков в Авито Подработка, аспирант. **Тема:** Статистический анализ и визуализация данных, введение в работу с данными и разведочный анализ.

### 1. Фундаментальные понятия: От данных к решениям

Процесс работы с информацией проходит четыре ключевых этапа:

|Понятие|Определение (из источников)|Пояснение простым языком|
|:--|:--|:--|
|**Данные**|Сырые факты, цифры, символы, события, которые еще не имеют смысла без контекста.|Это как **отдельные кирпичики** — сами по себе они не говорят, что это будет за здание, пока их не собрать вместе.|
|**Информация**|Данные, приведенные в систему и осмысленные. Отвечают на вопрос: «Что это значит?».|Это когда мы из кирпичиков сложили **стену**. Мы видим структуру и понимаем, что это часть чего-то большего.|
|**Знания**|Интерпретация информации с учетом опыта, закономерностей, контекста. Отвечают на вопросы: «Почему это так?» и «Что из этого следует?».|Это когда мы понимаем, что стена стоит, потому что у нее **правильный фундамент**, и значит, мы можем строить дальше.|
|**Решения**|Применение знаний для действий и стратегий. Отвечают на вопрос: «Что делать?».|Это **само строительство** — действия, основанные на нашем понимании (знаниях).|

### 2. Типы данных

Данные делятся на **числовые** и **категориальные**, а также другие типы, такие как текст, изображения и аудио.

#### А. Числовые (Numerical)

1. **Непрерывные (Continuous):** Могут принимать любые значения в диапазоне.
    - _Примеры:_ цена товара, расстояние до пользователя, время до первой сделки.
    - _Интуитивное пояснение:_ Все, что можно **измерить** с дробной точностью (например, температура: 25.5°C).
2. **Дискретные (Discrete):** Ограниченные целые значения.
    - _Примеры:_ количество фотографий в объявлении, число просмотров, число сообщений.
    - _Интуитивное пояснение:_ Все, что можно **посчитать поштучно** (например, количество заказов: 3 или 4, но не 3.5).

#### Б. Категориальные (Categorical)

1. **Номинальные (Nominal):** Категории, которые не имеют естественного порядка.
    - _Примеры:_ тип товара («телефон», «велосипед»), регион, способ доставки.
    - _Интуитивное пояснение:_ Просто **названия** или метки, которые нельзя отсортировать от "лучшего" к "худшему" (например, цвета).
2. **Порядковые (Ordinal):** Категории, имеющие естественный порядок.
    - _Примеры:_ состояние товара («новый», «хороший», «средний»), уровень аккаунта («базовый», «премиум»).
    - _Интуитивное пояснение:_ **Ступеньки** или уровни, которые можно ранжировать (например, оценка 5 звезд лучше, чем 1 звезда).

#### В. Другие типы данных

- **Текст:** Заголовки, описания, отзывы, сообщения. Это особенно важно в современную эпоху (например, популярность Telegram).
- **Изображения/Видео:** Фотографии товара или видеообъявления.
- **Аудио:** Звонки, голосовые сообщения (часто транскрибируются в текст для моделирования).

### 3. Разведочный анализ данных (EDA)

**Разведочный анализ данных (EDA)** — это системный подход, чтобы понять структуру, качество и «поведение» данных до начала их моделирования.

**Главная цель EDA:** Понять, что представляют собой данные, выявить их особенности и ограничения.

**Почему это важно:** Это позволяет сформулировать корректные гипотезы, выбрать подходящие методы анализа и снизить риски ошибок/неверных выводов.

#### Задачи EDA

1. **Понимание структуры данных:** Изучение таблиц, полей, типов признаков, проверка уникальности ключей и связей.
2. **Изучение распределений:** Расчет средних, медиан, квантилей; поиск **выбросов** (экстремальных значений).
3. **Работа с пропусками и дубликатами:** Определение доли пропусков и поиск повторяющихся записей.
4. **Анализ временных и геоданных:** Выявление **сезонности**, трендов и **аномалий** (например, сезонное падение трафика из-за начала учебного года).
    - _Интуитивное пояснение:_ Понимание сезонности — это как знать, что мороженое лучше продается летом, а не зимой.
5. **Анализ связей между признаками:** Проверка **корреляций** и зависимостей, чтобы выдвинуть первые гипотезы о факторах, влияющих на целевую переменную.
6. **Выявление проблем качества данных:** Ошибки логирования, несоответствия форматов (например, когда число записано как текст/строка — стринга).
7. **Формулировка гипотез:** Создание идей о том, какие признаки могут быть полезными и какие сегменты пользователей различаются по поведению (например, пользователи делают только один заказ и уходят).

### 4. Инструменты EDA

Для работы с данными используются различные инструменты и библиотеки.

#### Основные инструменты

- **SQL (Structured Query Language):** Язык для работы с базами данных. Используется для извлечения данных (первых выборок, агрегаций) из БД, но сам EDA, как правило, проводится не на SQL. Требует оптимизации при работе с большими данными.
- **Python:** Ключевой инструмент, обширно покрывающий все задачи работы с данными.
- **BI-системы (Tableau, Superset, DataLens):** Используются для создания интерактивных дашбордов и отслеживания динамики.

#### Ключевые библиотеки Python

|Библиотека|Назначение|Пояснение простым языком|
|:--|:--|:--|
|**Pandas**|Базовая библиотека для работы с табличными данными (DataFrame/Series). Используется для загрузки, очистки, трансформации данных, фильтрации, сортировки, объединения (джойны/мерджи).|Это **"Excel на стероидах"** в Python. Он позволяет работать с таблицами (датафреймами) как с переменными и обрабатывать миллионы строк за секунды, не зависая, как Excel.|
|**NumPy**|Базовая библиотека для работы с многомерными массивами (ndarray) и быстрыми численными операциями. Используется для расчетов агрегатов, векторных расчетов, подготовки фичей для моделей.|**"Быстрый калькулятор"** для сложных операций с большими наборами чисел.|
|**Matplotlib / Plotly / Seaborn**|Библиотеки для визуализации. Matplotlib — базовая графика; Plotly — интерактивная графика; **Seaborn** — библиотека для статистических графиков, более "высокоуровневая" и лучше интегрирована с Pandas.|Инструменты, чтобы **"нарисовать"** ваши данные (распределения, связи, сезонность).|
|**SciPy / Statsmodels**|Набор статистических функций и моделей. Используются для проверки распределений, корреляций, значимости различий (например, T-тест, тест Манна-Уитни).|**"Лаборатория статистики"** для проведения тестов и проверки гипотез.|
|**SQLAlchemy**|Позволяет подключаться к СУБД (системам управления базами данных) и получать данные из SQL-запроса сразу в DataFrame.|**"Мост"** между Python и базами данных, позволяющий напрямую забрать табличку.|
|**PySpark**|Инструмент для обработки очень больших данных (Big Data).|**"Конвейер"** для быстрой обработки огромных массивов информации.|

**Рабочая среда:** Рекомендуется использовать **Jupyter Notebook** или **Google Colab** (бесплатный облачный сервис, не требующий локальной установки). Библиотеки устанавливаются командой `!pip install [название библиотеки]`.

### 5. Первичная проверка данных (Первый шаг EDA)

Это базовые шаги, которые необходимо выполнить, получив незнакомый датасет.

#### 5.1. Обзор и корректность данных

- **Проверка размера:** Использование функций `df.shape` (размер), `df.head()` (первые строки) и `df.tail()` (последние строки).
- **Проверка диапазонов:** Функция `df.describe()` показывает минимальные, максимальные, средние и медианные значения по столбцам, что позволяет выявить аномалии (например, отрицательные цены).
- **Проверка форматов:** Использование `df.info()` для определения типов столбцов (например, `int`, `float`, `object`). **Важная проблема:** Числовые значения могут быть ошибочно даны как текст (стринг/объект), что не позволит посчитать среднее или медиану.
- **Проверка уникальных значений:** Для категориальных признаков используются `df['col'].unique()` (посмотреть уникальные значения) и `df['col'].nunique()` (посчитать их количество). Это помогает найти одинаковые значения в разных регистрах ("Москва" / "москва").

#### 5.2. Работа с дубликатами

**Проблема:** Дублей необходимо избегать, так как они искажают статистику (суммы, средние, частоты), приводят к повторному учету объектов и могут вызывать **переобучение** моделей.

- _Интуитивное пояснение:_ Если вы посчитаете один и тот же заказ дважды, ваша статистика продаж будет неверна.
- **Как бороться:** Использовать функцию `drop_duplicates()`. Важно понимать причину дублей, прежде чем их удалять (например, могли быть ошибки при сборе или объединении таблиц).

#### 5.3. Работа с пропусками (Missing Values, NA)

**Проблема:** Пропуски (NaN) опасны, поскольку искажают статистику и корреляции, вызывают ошибки в обучении моделей и визуализации.

- **Как проверить:** Использовать `df.isna().sum()` для подсчета количества пропусков в каждом столбце.
- **Способы избавления от пропусков (Импутация):**
    1. **Удаление (Drop NA):** Жесткий способ, подходит, если доля пропусков невелика (<5%).
    2. **Заполнение (Imputation):** Замена пропусков:
        - _Для числовых:_ Средним, медианой или нулем (будьте осторожны с нулем, он может занизить среднее).
        - _Для категориальных:_ Значением «Unknown» или модой (самым популярным значением).
        - _Для временных рядов:_ Интерполяцией или заполнением соседними точками (`ffill`/`bfill`).
    3. **Отметка флагом:** Создание отдельной колонки, указывающей, был ли в исходном столбце пропуск. Это полезно для моделирования.
- **Принцип работы:** Сначала нужно исследовать, почему пропуски возникли, а только потом заполнять их.

#### 5.4. Метаданные

**Метаданные** — это «данные о данных», информация, которая описывает структуру, смысл, источники и ограничения самих данных.

- _Интуитивное пояснение:_ Это **"инструкция по эксплуатации"** датасета.
- **Ценность:** Помогают понять контекст признаков, выбрать правильные методы анализа (например, нельзя считать среднее по строке), контролировать качество данных и облегчают передачу знаний.
- **Что включают метаданные:**
    - Общая информация (источник, объем, дата получения).
    - **Паспорт признаков** (описание переменных): Название поля, тип (float, int, object), краткое описание, единицы измерения, диапазон допустимых значений и наличие пропусков.
    - Технические характеристики (кодировка, формат хранения).
    - Качество данных (доля дублей и выбросов).

### Примеры влияния EDA на бизнес

1. **Проблема с верификацией (Avito Подработка):** Было обнаружено, что каждая десятая загрузка медицинской книжки происходила _до_ верификации личности через Госуслуги. Это приводило к ошибкам у пользователей.
    - **Решение:** На основе EDA пересобрали путь пользователя (CJM), чтобы Госуслуги были обязательны перед загрузкой медкнижки. Это быстро решило проблему.
2. **Низкое качество фото для рекламы (Avito Авто):** Анализ выявил, что для контекстной рекламы (Яндекс Директ) отправляются фотографии автомобилей в ужасном состоянии (ржавые, грязные).
    - **Решение:** Разработали модель, которая автоматически оценивает качество автомобиля на фото, чтобы для рекламы выбирать более привлекательные изображения.

---

**Совет по запоминанию функций (от эксперта и коллег):** Самый лучший способ запомнить функции Pandas — **практиковаться** (по сути, да). Также можно вести личный конспект в Jupyter Notebook (используя `markdown` ячейки для текста и пояснений) с примерами функций.