**Подробный конспект лекции: Данные от получения до понимания структуры**

Данный конспект основан на вводном занятии, которое открывает цикл, посвященный работе с данными. Цикл занятий ведут специалисты из Avito, ИТМО и Газпромнефти. Сегодняшняя лекция является вводной, с меньшим количеством практики и большим погружением в устройство работы с данными на практике, в том числе в Avito.

### I. Общая информация о курсе и спикере

- **Спикер (Дмитрий)** является выпускником Финансового университета и аспирантом, занимающимся наукой в области маркетинговой аналитики.
- Он занимает должность **ведущего (lead) исполнителя** в сервисе Avito "Подработка" — сервисе краткосрочной занятости.
- **Avito** — это большая классифайд-площадка, охватывающая работу, авто, недвижимость, товары (гудсы) и другое. Avito исторически является одной из сильнейших компаний в России в области аналитики и внедряет много передовых практик (best practices).
- Спикер проведет **четыре занятия**:
    - Тема 1: Разведочный анализ данных (Exploratory Data Analysis, EDA).
    - Тема 2: Очистка и подготовка датасета.
- В работе будут использоваться такие инструменты, как **Python** (Питон) и **SQL** (язык работы с базами данных). Занятия будут проходить в Jupiter Hub или Colab, ориентируясь на базовый уровень подготовки студентов.

**Правила курса:**

- Вопросы задаются в чате для эффективной работы и документирования.
- Необходимо активно участвовать в решении задач, которые начнутся со второго или третьего занятия.
- Поддерживается культура безопасности: не стоит бояться ошибок, любая мысль имеет место.

### II. Устройство работы с данными в Avito

Работа с данными в Avito глобально упрощается до следующей схемы: Источники данных $\rightarrow$ ДВХ (Хранилище) $\rightarrow$ BI-системы/Платформы.

#### 1. Источники данных

Источники данных — это различные поверхности и элементы, откуда поступают данные.

- **Фронт (Front-end):** Все, что пользователь видит и с чем взаимодействует (клики, просмотры, нажатия, ввод текста). Все эти действия являются **событиями** (Clickstream) и отправляются в хранилище.
- **Бэк (Back-end):** Сервисы, работающие "под капотом" (например, изменение статуса заказа, верификация аккаунта). В микросервисной архитектуре, которую использует Avito, каждый сервис имеет свою базу данных, откуда аналитики забирают данные.
- **Экстракты:** Костыльные (нежелательные) способы, когда бизнес хранит данные в Excel или Google Docs, и аналитики парсят эти файлы для загрузки в ДВХ.
- **Ad-hoc выгрузки:** Разовые загрузки данных.

**Важный аспект: Анонимность**

- Все события логируются анонимно. **Невозможно** связать события с конкретным лицом (ФИО, номер телефона).
- Связь данных с конкретным лицом возможна только в случаях, когда пользователь сам дал на это разрешение (например, заполнил анкету или прошел верификацию через Госуслуги/банки, что требует отдельного согласия при каждой операции).
- Аналитики работают с пользователями как с уникальными **ID** (идентификаторами).

#### 2. ДВХ (Хранилище данных)

ДВХ (Data Warehouse, или Data Lake — Озеро данных) — это большая система, которая хранит, обрабатывает и агрегирует миллионы и миллиарды строк данных.

- **СУБД (Системы управления базами данных):** Управляют множеством таблиц и процессами загрузки.
    - Ранее использовалась **Vertica**.
    - Сейчас используются **Trino** (Open Source) и **ClickHouse** (российская разработка, быстрая СУБД, отлично подходит для обработки событий).
- **Требования к хранению данных:**
    - У каждой таблицы должна быть **схема**.
    - В таблице должен быть **Primary Key** (уникальный ключ, ID).
    - Должны использоваться **Foreign Keys** (внешние ключи) для связывания таблиц (например, таблица заказов связана с таблицей пользователей).
- **Автоматизация:** Процессы загрузки данных, расчета А/Б тестов и визуализации должны быть автоматизированы.
- **Best Practice:** **Дата-каталоги** — документация, описывающая сущности, хранимые в таблицах (ключи, значения, формат).

#### 3. BI-системы и платформы

BI-платформы — это способ взаимодействия стейкхолдеров (пользователей) с данными, обеспечивающий оперативное принятие решений.

- **Конечная цель данных:** Не просто цифры, а **выводы и решения**, которые помогут улучшить продукт и бизнес.
- **Платформа 3 Sigma:** Разработана Avito и используется для сторонних компаний. В ней происходит расчет **А/Б тестов** и отслеживание метрик.
- **Best Practice:** **Реестр метрик** — необходим для больших компаний. Он закрепляет единую методологию расчета каждой метрики за одним ответственным, чтобы избежать разногласий между отделами.

**А/Б Тестирование (A/B Testing)**

- Это практика, пришедшая из медицины (плацебо, контрольные группы).
- Проверка эффективности изменений путем сравнения двух групп пользователей: одна видит изменение (тестовая группа), другая — нет (контрольная группа).
- Анализируется статистически значимая разница между группами с помощью методов статистики (t-тесты, Манна-Уитни).
- Платформы, такие как 3 Sigma, автоматизируют этот процесс.

### III. Роль аналитика и Data-подход

#### 1. Роли в работе с данными

Работа с данными включает роли:

- **Data Engineers (Дата-инженеры):** Создают сервисы и процессы работы с данными (наиболее удалены от бизнеса).
- **Разработка (Development):** Собирает данные и проектирует БД.
- **Data Scientists и Data Analysts:** Собирают данные, проводят исследования и доносят выводы.

**Основные задачи аналитика**:

1. **Создание событий:** Проектирование аналитических событий (дизайн того, как и что должно передаваться и храниться).
2. **Создание витрин** (нужных табличек).
3. **Создание дашбордов**.
4. **Создание метрик** и их методологии расчета.
5. **Документирование** и представление выводов.
6. **Перелив данных**.

**Эволюция аналитики и роль ИИ:**

- Рутинная "хокковая аналитика" (выгрузки списков) является неинтересной и нецелевой задачей для аналитика.
- ИИ (GPT) способен заменить часть такой работы, особенно если база данных хорошо описана.
- Ценность аналитика заключается в **сервисной аналитике** — создании сложных аналитических инструментов, моделей, исследований, сегментации и разработке методик (например, атрибуционные модели).

#### 2. Data-Driven подход

В бизнесе используются два подхода:

- **Data-Informed (Информированный):** Принятие решений происходит на основе данных, но субъективно (посмотрели на график, решили, что "кажется, выросло, давайте катить").
- **Data-Driven (Основанный на данных):** Любое изменение проходит верификацию данных, и решение принимается объективно на основе статистических доказательств (как в медицине). Это минимизирует риски неправильной интерпретации (например, из-за сезонности или некорректной выборки).

#### 3. Примеры бизнес-кейсов, основанных на данных

- **Рекомендация товаров:** Алгоритмы показывают релевантные объявления, что ведет к росту заинтересованности и кликов.
- **Борьба с мошенничеством (Антифрод):** Используются поведенческие и заградительные системы (верификация Госуслугами). Это огромный департамент, который, как правило, выбирает **долгосрочный репутационный эффект (LTV)**, даже если это означает потерю краткосрочной прибыли от блокировки мошенников.
- **Анализ изображений (Мультимодальность):** Используется для оценки качества товара (например, модель определяет, можно ли разбитый автомобиль показывать в рекламе).
- **Прогнозирование цен и спроса:** Профессиональные продавцы получают прогнозы спроса и потенциальных просмотров.

#### 4. Вызовы и ограничения в работе с данными

1. **"Грязные" данные:** Данные всегда содержат ошибки из-за технических сбоев, задвоений или отключения сервисов. Первым шагом при изменении метрики является проверка корректности самих данных.
2. **Правовые и этические ограничения:** Нельзя использовать данные без согласия пользователя. Законодательство регулирует, что является персональными данными (например, адрес является персональным, город — нет). В Avito очень жесткий подход к безопасности; многие продуктовые идеи отклоняются юристами ради кибербезопасности и избежания штрафов.
3. **Технологические ограничения:** Инфраструктура ограничивает обработку. Например, многие витрины в ДВХ обновляются с задержкой в один день, так как обновление каждые 10 минут требует огромных ресурсов.
4. **Интерпретация данных:** **Корреляция не означает причинно-следственную связь** (колузацию). А/Б тесты — инструмент для оценки того, действительно ли изменение А приводит к эффекту В.

### IV. Метрики и целеполагание

#### 1. Метрики и Дерево метрик

- **Метрика** — это методология или принцип, по которому рассчитывается конкретное значение (например, количество активных пользователей).
- **Главное** — корректный и правильный выбор метрики, так как неправильный выбор искажает смысл выводов.
- **Дерево метрик** необходимо для понимания взаимосвязи между показателями (например, выручка связана с новыми покупателями и повторными покупками). Оно помогает аналитику определить, откуда тянется проблема при падении ключевого показателя.

#### 2. North Star Metric (NSM)

- **NSM (Путеводная звезда)** — это целевая метрика, к которой стремится компания.
- **Значение:** Она помогает приоритизировать инициативы и действия команды, когда ресурсов не хватает (например, выбирается инициатива, которая дает наибольший вклад в NSM).
- Метрика должна быть устойчивой к манипуляциям (например, нельзя вырастить конверсию, просто уменьшив знаменатель).
- **Пример NSM для Avito:** **LTV (Lifetime Value)** — ценность, которую пользователь генерирует для сервиса (просмотры, сделки).
- **Примеры для других бизнесов:**
    - Маркетплейсы: Число успешных контактов.
    - SaaS: Число активных пользователей, совершающих ключевое действие.
    - Финтех: Количество транзакций.