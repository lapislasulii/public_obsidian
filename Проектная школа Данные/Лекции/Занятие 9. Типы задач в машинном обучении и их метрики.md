[[L9_Типы_задач_ML_и_разметка_данных_final.pdf]]
## Подробный конспект занятия по анализу данных

### 1. Три основные парадигмы машинного обучения (МО)

Машинное обучение классифицируется по тому, как модель обучается на данных. Выбор парадигмы зависит от наличия размеченных данных и характера решаемой задачи.

|Парадигма|Описание (Простым языком)|Задачи|
|:--|:--|:--|
|**Обучение с учителем** (Supervised Learning)|**Модель учится по примерам с правильными ответами.** Это как учить ребенка по карточкам: для каждого объекта заранее известна правильная метка или значение целевой переменной (ответ). Модель пытается извлечь логику из данных, чтобы научиться давать эти ответы самостоятельно.|Классификация, Регрессия.|
|**Обучение без учителя** (Unsupervised Learning)|**Модель самостоятельно ищет закономерности в данных.** У модели нет "правильных ответов". Модель ищет естественные группировки или скрытые структуры.|Кластеризация, снижение размерности, выявление аномалий.|
|**Обучение с подкреплением** (Reinforcement Learning)|**Модель учится через "опыт" и обратную связь.** Это как дрессировка: агент (модель) взаимодействует со средой и получает награды или штрафы за свои действия, чтобы принимать оптимальные решения.|Робототехника, игры, системы управления.|

---

### 2. Типы задач в машинном обучении и их метрики

Выбор типа задачи определяется характером целевой переменной.

#### А. Классификация (Classification)

**Суть задачи:** **Предсказание категориальной переменной** (класса). Цель — отнести объект к одной из нескольких категорий.

- _Интуитивно:_ Это задачи "да/нет" или "какой из этих вариантов". Например: распознать, кошка на картинке или собака, или отнести письмо к спаму или не спаму.
- **Постановка задачи:** По выборке $(x_i, y_i)$, где $y_i$ — это класс из набора ${1, 2, ..., K}$, построить модель $f: X \rightarrow Y$ для предсказания класса.

##### Основные метрики классификации

Для оценки точности модели используется **Матрица ошибок (Confusion Matrix)**, которая позволяет детально понять, где модель ошибается, сравнивая предсказанные и фактические ответы.

|Термин|Определение (Простым языком)|
|:--|:--|
|**Accuracy (Точность)**|**Общая доля правильных предсказаний** среди всех объектов. _Недостаток:_ Ненадежна, если классы несбалансированы (одного класса в данных намного больше, чем других).|
|**Precision (Точность)**|**Насколько мы правы, когда говорим "да"?** Доля правильных положительных предсказаний среди всех объектов, которые модель предсказала как положительные.|
|**Recall (Полнота)**|**Какую долю "да" мы смогли найти?** Доля найденных истинно положительных объектов среди всех реально положительных.|
|**F1-Score**|**Гармоническое среднее Precision и Recall.** Часто используется как **золотой стандарт**, поскольку позволяет учесть обе ошибки (ложноположительные и ложноотрицательные) и эффективна при дисбалансе классов.|

#### Б. Регрессия (Regression)

**Суть задачи:** **Предсказание непрерывной переменной** (числа). Цель — найти закономерность (линию или кривую) между признаками и целевой переменной.

- _Интуитивно:_ Задача предсказания числового значения. Например: прогнозирование цены на дом, курса валют, веса по росту.
- **Постановка задачи:** По выборке $(x_i, y_i)$, где $y_i$ — это непрерывное значение ($y_i \in \mathbb{R}$), построить модель $f: X \rightarrow \mathbb{R}$.

##### Основные метрики регрессии

Метрики основаны на расчете ошибки — среднего расстояния между фактическим значением ($y_i$) и прогнозом модели ($\hat{y}_i$).

|Метрика|Описание (Простым языком)|Особенности|
|:--|:--|:--|
|**MSE (Mean Squared Error)**|**Среднеквадратичная ошибка.** Вычисляется как среднее значение квадратов разностей между прогнозом и истинным значением.|**Сильно штрафует большие ошибки** (из-за возведения в квадрат).|
|**MAE (Mean Absolute Error)**|**Средняя абсолютная ошибка.** Вычисляется как среднее значение абсолютных разностей.|**Более устойчива к выбросам**, чем MSE.|

#### В. Кластеризация (Clustering)

**Суть задачи:** **Поиск групп схожих объектов** в неразмеченных данных. Объекты должны быть схожи внутри кластера и различны между кластерами.

- _Интуитивно:_ Автоматическое сегментирование. Например: разбиение клиентов банка на группы по поведению, чтобы предложить релевантные скидки.
- **Постановка задачи:** Разбить набор объектов ${x_1, ..., x_n}$ без меток на $K$ кластеров.

##### Основные метрики кластеризации

Оценка качества базируется на **расстояниях** между объектами и кластерами.

- **Silhouette Score:** Измеряет, насколько хорошо объекты отделены друг от друга. Значения от -1 до 1. Высокие значения указывают на хорошее разделение кластеров.
- **Davies-Bouldin Index:** Еще один популярный индекс для оценки качества кластеризации.

---

### 3. Разметка данных (Data Labeling)

**Разметка данных** — это процесс присвоения меток (правильных ответов) или тегов сырым данным, что критически важно для обучения с учителем (Supervised Learning).

- _Интуитивно:_ Мы вручную сообщаем компьютеру, что́ есть что, чтобы он научился это делать сам. Без этого "учителя" модель не может обучаться.

#### Фундаментальные принципы разметки

1. **GIGO (Garbage In, Garbage Out):** **Качество данных определяет качество модели**. Если в модель загружаются "грязные данные" или данные с неправильной разметкой, то итоговый результат (модель) будет низкого качества.
    
    - **Последствия некачественной разметки:**
        - **Низкая точность предсказаний:** Модель усваивает ошибки разметки.
        - **Смещения и предвзятость (Bias):** Несогласованная разметка может привести к тому, что модель усвоит человеческие предрассудки (например, дискриминацию по полу или расе) и будет систематически ошибаться на определенных группах объектов.
        - **Неспособность обобщать:** Модель переобучается на шумных данных и не может корректно работать на новых, реальных данных.
        - **Потеря ресурсов:** Требуется повторный сбор и разметка, что ведет к потере времени и денег.
2. **Трудозатраты:** Разметка данных занимает около **80% времени** ML-проекта, связанного с подготовкой и обработкой данных.
    

#### Типы разметки по модальности данных

Разметка может принимать разные формы в зависимости от типа данных:

|Модальность|Типы разметки|Примеры целевой переменной (интуитивно)|
|:--|:--|:--|
|**Изображения**|Классификация, Object Detection (bounding boxes), Semantic Segmentation, Keypoint Detection.|Метка класса ("кошка"), координаты рамки, в которой находится объект, или закрашенная область (пиксели).|
|**Текст**|Классификация текста, Named Entity Recognition (NER), Question Answering.|Категория ("позитивный" отзыв), выделенные имена или адреса.|
|**Аудио**|Классификация звуков, Speech-to-Text, Emotion Recognition.|Текст, соответствующий речи, или метка ("звук чихания").|
|**Видео**|Action Recognition, Object Tracking, Video Segmentation.|Траектория движения объекта или метка события.|

#### Методы разметки данных

|Метод|Качество|Скорость|Стоимость|Описание|
|:--|:--|:--|:--|:--|
|**Ручная разметка**|Отличное|Медленно|Высокая|Человек (эксперт, краудсорсер) вручную присваивает метки.|
|**Полуавтоматическая**|Хорошее|Средне|Средняя|Комбинация автоматической предразметки и ручной проверки/коррекции.|
|**Автоматическая**|Среднее|Быстро|Низкая|Модель автоматически генерирует метки, иногда используя синтетические данные или Weak Supervision.|

#### Роль Больших языковых моделей (LLM) в разметке

LLM (например, GPT) — это модели глубокого обучения с миллиардами параметров, способные решать широкий класс задач NLP.

- **Преимущества:** LLM могут размечать тысячи примеров за минуты, обеспечивая высокую **скорость и масштабируемость**. Они обеспечивают **согласованный подход** и значительно снижают затраты.
- **Применение:** Классификация текстов, анализ тональности, выделение именованных сущностей (NER), генерация синтетических данных, автоматическая валидация.
- **Ограничения:** Требуют человеческой валидации, особенно для узкоспециализированных областей (медицина). LLM могут "галлюцинировать" (давать некорректные или выдуманные ответы).
- **Оптимальная стратегия:** **Гибридный подход.** Использование LLM для первичной автоматической разметки с последующей человеческой экспертизой и проверкой.

---

### 4. Практический пример: Использование LLM для автоматической разметки

На практике LLM, такие как GEMA 2, могут быть интегрированы в процесс разметки для создания новых целевых переменных, которых изначально нет в датасете.

- **Этапы:**
    1. **Определение задачи:** Выбрать задачу (например, оценить вероятность продажи дома в течение месяца, что является задачей классификации: Низкая, Средняя, Высокая вероятность).
    2. **Создание Про́мпта:** Сформулировать структурированный текстовый запрос (про́мпт), который включает все необходимые характеристики объекта (например, цена, площадь, количество спален дома).
    3. **Формализация ответа:** Четко указать LLM, в каком формате она должна ответить (например, "ответь только одним словом из списка: низкая, средняя или высокая вероятность").
    4. **Автоматическое применение:** Использовать функцию, которая генерирует про́мпт для каждой строки датасета и передает его LLM, собирая ответы.
    5. **Полуавтоматическая стратегия:** Включить человека в процесс: после автоматической разметки человек проверяет ответ модели и либо соглашается, либо вносит исправление, обеспечивая дополнительную валидацию и повышая качество разметки.

---

> **Интуитивное понимание (Аналогия):** Представьте, что машинное обучение — это строительство дома. **Разметка данных** — это фундамент. Если фундамент ("правильные ответы") сделан некачественно, дом (модель) будет неустойчивым, независимо от того, насколько сложный и дорогой у вас проект (алгоритм). **Классификация** — это выбор цвета стен (категория), а **Регрессия** — это расчет точного количества кирпичей (непрерывное число). **Кластеризация** — это разбиение материалов на кучи по схожести, когда вы не знаете, сколько куч получится. А использование **LLM** в разметке — это привлечение робота-специалиста, который быстро сделает черновую работу, но вы все равно должны проверить его, чтобы избежать ошибок и "галлюцинаций".