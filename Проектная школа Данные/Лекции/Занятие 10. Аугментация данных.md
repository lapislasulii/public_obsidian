
[[L10_Аугментация_данных_final.pdf]]
**Подробный конспект занятия: Аугментация данных**

Аугментация данных — это ключевой инструмент в машинном обучении, позволяющий решать проблему **недостатка и однообразия данных**.

---

### 1. Проблема и необходимость аугментации

Главная проблема в ML, которую решает аугментация, — это **недостаток данных**.

| Причина                              | Пояснение простым языком                                                                                                                                                                                            |
| :----------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Высокие затраты**                  | Сбор большого количества данных и их разметка (особенно в сложных областях, как медицина или юриспруденция) требуют много времени и денег.                                                                          |
| **Редкие события/Дисбаланс классов** | В данных могут быть классы, представленные очень малым количеством примеров (например, случаи мошенничества или редкие заболевания). Модели трудно учиться на том, чего она почти не видит.                         |
| **Последствия недостатка данных**    | Модель может **переобучиться**. Это значит, что она "запоминает" обучающую выборку вместо того, чтобы изучить общие правила. В результате модель плохо работает на новых, невиданных данных (плохая генерализация). |

**Решение:** Аугментация данных искусственно увеличивает размер и разнообразие обучающей выборки, что является экономически эффективным способом повышения качества модели.

---

### 2. Определение и ключевые принципы

**Формальное определение:** Аугментация данных — это процесс искусственного увеличения объема и разнообразия обучающих данных. Это достигается путем применения к исходным примерам различных **преобразований**, которые **сохраняют семантику и метки данных**, но создают новые вариации.

**Пояснение простым языком (Интуитивное понимание):** Аугментация — это процесс создания "поддельных", но очень реалистичных, новых примеров из тех, что у нас уже есть. Мы слегка меняем старые примеры, чтобы модель видела больше вариаций, но при этом гарантируем, что суть примера (его метка или класс) остается прежней.

**Ключевые принципы аугментации:**

1. **Сохранение меток:** Преобразования не должны менять класс или целевую переменную исходного примера.
2. **Реалистичность:** Синтетические данные должны быть похожи на реальные и соответствовать практическим условиям. (Например, нельзя поворачивать цифру '6' так, чтобы она стала '9').
3. **Разнообразие:** Преобразования должны создавать достаточную вариативность, чтобы помочь модели обобщать.

---

### 3. Связь с Feature Engineering (FE)

Аугментация и Feature Engineering (создание новых признаков) могут использоваться вместе для максимальной информативности датасета.

|Метод|Направление расширения|Что меняется в данных|Пояснение простым языком|Источник|
|:--|:--|:--|:--|:--|
|**Feature Engineering (FE)**|**Расширение по горизонтали** (столбцы)|Увеличивает количество признаков (столбцов).|Вы добавляете больше характеристик (например, рассчитываете статистику или комбинируете существующие столбцы).||
|**Аугментация**|**Расширение по вертикали** (строки)|Увеличивает количество примеров (строк).|Вы добавляете больше объектов/наблюдений в ваш датасет на основе существующих.||

**Оптимальная стратегия:** Сначала следует применить Feature Engineering, чтобы создать информативные признаки, а затем использовать аугментацию для увеличения количества примеров.

---

### 4. Аугментация в ML пайплайне (последовательность действий)

Правильная последовательность шагов критически важна для получения объективных результатов.

1. **Разделение данных:** Исходный датасет обязательно делится на обучающую (Train) и тестовую (Test) выборки.
2. **Feature Engineering:** Применяется к обучающей выборке (Train).
3. **Аугментация:** Применяется **только к обучающей выборке** (Train).
4. **Обучение и валидация:** Модель обучается на аугментированных данных.
5. **Тестирование:** Тестирование и оценка качества модели (метрики) проводятся **строго на исходных (не аугментированных) тестовых данных**.

**Пояснение простым языком (Почему нельзя аугментировать тестовые данные):** Если вы аугментируете тестовые данные, вы рискуете получить ложно завышенные метрики (утечка данных). Когда модель выйдет в реальный мир (в "прод"), она столкнется с "чистыми" данными, и ее реальная производительность окажется сильно хуже, чем показано на завышенных метриках.

---

### 5. Методы аугментации по модальностям

#### А. Компьютерное зрение (Изображения)

В этой области аугментация используется практически всегда, так как вариативность данных легко обогатить.

- **Геометрические преобразования:** Поворот, отражение, масштабирование, обрезка, сдвиг, деформация. (Интуитивно: Имитация разных ракурсов и частичного попадания объекта в кадр).
- **Фотометрические преобразования:** Изменение яркости, контраста, насыщенности, цветового баланса, добавление шума. (Интуитивно: Имитация разных условий освещения и низкого качества съемки).
- **Продвинутые методы:** **Cutout/Random Erasing** (случайное удаление частей изображения, чтобы модель не фокусировалась на одной детали) и **Mixup & CutMix** (смешивание двух изображений и их меток).

#### Б. Текст и Аудио

- **Аугментация текста (NLP):**
    - **Замена синонимами:** Замена слов на синонимы без потери смысла.
    - **Обратный перевод (Back-Translation):** Перевод текста на другой язык и обратно для получения новой формулировки.
    - **Случайные операции:** Вставка, удаление или перестановка слов для добавления шума.
    - **Генеративные модели (LLM):** Использование больших языковых моделей для генерации парафраз и семантически эквивалентных текстов.
- **Аугментация аудио:**
    - **Добавление шума:** Наложение фоновых шумов (улица, другие голоса) для повышения устойчивости (робастности) модели к реальным условиям.
    - **Изменение скорости и высоты тона (Time/Pitch Shift):** Имитация разной скорости речи и тембра голоса.

---

### 6. Методы аугментации табличных данных

Табличные данные аугментируют реже, но это необходимо при сильном дисбалансе классов или малом количестве примеров.

#### А. Добавление шума (Noise Injection)

- **Описание:** Простой и быстрый метод: к числовым признакам добавляется небольшой **гауссовский шум**.
- **Пояснение простым языком:** Вы берете исходное числовое значение и слегка его "шевелите", добавляя маленькое случайное отклонение. Это создает вариации данных, сохраняя при этом их статистические свойства.
- **Преимущества:** Простота, скорость, хорошая регуляризация.
- **Математика (Интуитивно):** Новое значение = Исходное значение + Случайное число, взятое из нормального распределения с очень маленьким средним и небольшим стандартным отклонением ($\epsilon \sim N(0, \sigma^2)$).

#### Б. SMOTE (Synthetic Minority Over-sampling Technique)

- **Описание:** Метод для борьбы с дисбалансом классов. Он генерирует синтетические примеры для миноритарного класса путем **интерполяции** (нахождения среднего значения) между существующими точками данных и их ближайшими соседями в признаковом пространстве.
- **Пояснение простым языком:** SMOTE работает как заполнение пробелов. Если у вас есть два редких примера (точки) одного класса, SMOTE проводит между ними линию и создает новую "фейковую" точку на этой линии. Это позволяет увеличить плотность редких данных.
- **Особенность:** SMOTE генерирует одинаковое количество примеров для всех точек миноритарного класса.

#### В. ADASYN (Adaptive Synthetic Sampling)

- **Описание:** Улучшенная версия SMOTE. ADASYN адаптивно определяет, сколько синтетических примеров нужно создать, в зависимости от сложности окружения точки.
- **Пояснение простым языком:** ADASYN более "умный". Он понимает, где граница между классами наиболее сложная или "размытая". Он фокусируется на этих трудных местах и создает там больше синтетических примеров, чтобы модель могла лучше научиться разделять классы.

#### Г. Генеративные модели

Использование VAE (Вариационных автоэнкодеров) или GAN (Генеративно-состязательных сетей) для генерации новых, статистически похожих записей с сохранением корреляций между признаками.

---

### 7. Лучшие практики и выводы

- **Контроль силы преобразований:** Избегайте чрезмерных искажений, которые могут создать нереалистичные данные.
- **Соответствие домену:** Выбирайте преобразования, которые соответствуют реальным искажениям и физически возможным значениям в вашей области применения (например, в медицине или юриспруденции).
- **Оценка качества:** Успешная аугментация требует итеративного подхода. Проверяйте качество аугментации не только по метрикам модели, но и **визуально** (например, с помощью гистограмм или TSNE). Необходимо убедиться, что распределение аугментированных данных максимально близко к распределению исходных данных.

**Ключевой вывод:** Аугментация — это мощный и творческий инструмент, который повышает разнообразие данных, ведет к улучшению обобщающей способности модели и ее устойчивости (робастности) к новым данным, часто позволяя сэкономить на дорогостоящем реальном сборе данных.