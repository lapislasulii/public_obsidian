# Конспект лекции 1. Численные методы: Введение и интерполяция

### 1. Введение: Зачем нужны численные методы?

Курс численных методов является фундаментальным «пререквизитом» для более сложных дисциплин, таких как **методы оптимизации**.

-   **Мотивация:** В реальной жизни многие математические задачи не имеют красивого аналитического решения (формулы), либо эти решения слишком сложны для вычислений. Численные методы позволяют найти приближенное решение с заданной точностью там, где «чистая» математика бессильна.
-   **Связь с практикой:** Методы оптимизации, вытекающие из численных методов, лежат в основе обучения нейронных сетей (например, метод градиентного спуска).
-   **Основные задачи курса:** Весь курс будет посвящен тому, как эффективно представлять сложные функции в более простом виде. В частности, это аппроксимация (приближение) функций, численное интегрирование, дифференцирование и решение систем линейных уравнений.

---

### 2. Задача интерполяции (Приближение функций)

Первая большая тема курса — **Приближение функций и смежные вопросы**.

**Определение:** Пусть функция $f(x)$ задана таблично в точках (узлах) $x_i$ своими значениями $f(x_i)$. Задача интерполяции — построить многочлен $Q(x)$, который в этих узлах будет **в точности совпадать** со значением функции: $Q(x_i) = f(x_i)$.

-   **Зачем это нужно?** Исходная функция может быть очень сложной для вычислений или вообще неизвестной (например, набор данных из эксперимента). Многочлен (полином) — это простейшая структура, которую легко дифференцировать, интегрировать и программировать.
-   **Интуиция:** Представьте, что у вас есть набор точек на графике. Интерполяция — это проведение линии строго через эти точки. Внутри интервалов между точками линия должна «максимально приближать» поведение исходной функции, чтобы «угадать» значения функции между точками.

---

### 3. Базис и проблема «прямого» решения СЛАУ

Обычно многочлен ищется в виде суммы линейно независимых функций $\phi_k(x)$ с коэффициентами $a_k$:
$$Q(x) = \sum_{k=0}^{m} a_k \phi_k(x)$$
-   **Базис:** Для построения многочлена используется набор **линейно независимых функций** (базис). Самый простой и часто используемый пример — степенные функции: $1, x, x^2, \dots, x^m$.

#### Почему нельзя просто решить систему уравнений (СЛАУ)?

Теоретически, можно составить систему линейных уравнений для поиска коэффициентов $a_k$ (где $a_k$ — неизвестные). Матрица такой системы называется **матрицей Вандермонда**.

-   **Проблема:** В реальности узлы $x_i$ и значения функции $f(x_i)$ могут быть иррациональными или очень близкими числами. В таких случаях система становится плохо обусловленной. При решении системы возникают ошибки округления, точность катастрофически теряется, а сами вычисления становятся громоздкими.
-   **Пример:** При попытке приблизить функцию $\cos(x) \cdot \sin(x)$ через систему уравнений, коэффициенты могут получиться крайне неудобными для вычислений.

---

### 4. Интерполяционный многочлен Лагранжа

Для обхода решения громоздких систем и повышения устойчивости вычислений используется **метод Лагранжа**.

**Логика построения:** Мы хотим сконструировать такие «базисные» функции $L_k(x)$, которые в «своем» узле $x_k$ равны $1$, а во всех остальных узлах — $0$. Тогда итоговый многочлен — это просто сумма $f(x_k) \cdot L_k(x)$.

**Основные определения:**

1.  **Вспомогательная функция $\omega(x)$:** Это произведение всех скобок $(x - x_0)(x - x_1)\dots(x - x_n)$. Это многочлен, корнями которого являются все наши узлы интерполяции.
2.  **Функция $\omega_k(x)$:** Это та же $\omega(x)$, но из неё «выкинута» скобка, соответствующая $k$-му узлу.
    $$\omega_k(x) = \frac{\omega(x)}{x - x_k}$$
    -   _Свойство:_ $\omega_k(x_i) = 0$, если $i \neq k$. Если же подставить $x_k$, получится не ноль.
3.  **Множители Лагранжа $L_k(x)$:** Это нормированная функция $\omega_k(x)$, деленная на её значение в точке $x_k$.
    $$L_k(x) = \frac{\omega_k(x)}{\omega_k(x_k)}$$
    -   **Интуиция:** $L_k(x)$ — это «переключатель». В узле $x_k$ она равна **1**, а во всех остальных узлах — **0**. Это отношение гарантирует, что в точке $x_k$ результат будет $1$, а в любой другой узловой точке — $0$ (так как в числителе останется скобка, зануляющая выражение).

**Итоговая формула полинома Лагранжа:**
$$L_n(x) = \sum_{k=0}^n f(x_k) L_k(x)$$
-   **Мотивация:** Каждое слагаемое в этой сумме «отвечает» только за свою точку. Когда мы подставляем узел $x_i$, все слагаемые, кроме $i$-го, зануляются, а $i$-е слагаемое дает $f(x_i) \cdot 1$. Это избавляет нас от необходимости решать системы уравнений, так как многочлен автоматически проходит через все заданные точки.

---

### 5. Остаточный член интерполяции (Ошибка)

**Определение:** Разность между реальным значением функции $f(x)$ и значением интерполяционного многочлена $Q_n(x)$ называется **остаточным членом** $R_n(x) = f(x) - Q_n(x)$.

**Теорема о погрешности:**
$$R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \omega(x)$$
где $\xi$ — некоторая точка на отрезке, содержащем узлы интерполяции и точку $x$.

#### Идея доказательства формулы ошибки:

1.  Вводится вспомогательная функция $\varphi(t)$, которая имеет $n+1$ корней в узлах интерполяции $x_0, \dots, x_n$ и еще один корень в произвольной точке $x$ (всего $n+2$ корня).
2.  **Параллель с матанализом:** Согласно **теореме Ролля**, если функция зануляется в $N$ точках, то её производная зануляется как минимум в $N-1$ точках.
3.  Применяя теорему Ролля последовательно $n+1$ раз, мы доказываем, что $(n+1)$-я производная функции $\varphi(t)$ должна иметь хотя бы один корень (обозначим его $\xi$).
4.  Из этого условия выводится итоговая формула ошибки.
-   **Связь с прошлым:** Эта формула очень похожа на остаточный член **формулы Тейлора**. Разница в том, что в Тейлоре мы приближаем функцию в одной точке (используя производные), а здесь — в наборе распределенных точек.

**Оценка ошибки сверху:** Поскольку точное значение $\xi$ нам неизвестно, мы берем **максимум** модуля $(n+1)$-й производной на всем отрезке. Это дает нам **верхнюю оценку ошибки** — гарантированный предел, выше которого ошибка точно не поднимется.

---

### 6. Минимизация ошибки и многочлены Чебышёва

-   **Ловушка:** Кажется, что если добавить больше узлов (увеличить $n$), то точность интерполяции должна вырасти. **Это не всегда так!**
-   **Примеры (эффект Рунге):** Для некоторых функций (например, ступенчатая функция Хевисайда или специфические дроби) увеличение количества узлов приводит к тому, что многочлен начинает сильно «колебаться» (осциллировать) на краях отрезка, и ошибка только растет.

#### Как уменьшить ошибку?

Глядя на формулу остаточного члена $R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \omega(x)$, мы видим, что можем влиять на член $\omega(x) = (x-x_0)\dots(x-x_n)$. Нам нужно выбрать узлы $x_i$ так, чтобы **максимум модуля $\omega(x)$ был минимально возможным**.

Эту задачу решают **многочлены Чебышёва** ($T_n$).

-   **Определение:** Задаются рекуррентно:
    -   $T_0 = 1$
    -   $T_1 = x$
    -   $T_{n+1} = 2x T_n - T_{n-1}$
-   **Тригонометрическая форма:** На отрезке $[-1, 1]$ они представляются как $T_n(x) = \cos(n \arccos x)$. Это позволяет легко найти их корни (нули).

**Теорема (смысл):** Среди всех многочленов степени $n$ со старшим коэффициентом 1, именно пронормированный многочлен Чебышёва меньше всего отклоняется от нуля на отрезке $[-1, 1]$.

-   **Интуиция:** Эти многочлены «прижаты» к оси $x$ на отрезке $[-1, 1]$.
-   **Практический вывод:** Если в качестве узлов интерполяции брать корни многочлена Чебышёва, мы минимизируем риск возникновения огромных ошибок (того самого «дребезга» на краях), которые бывают при равномерном распределении узлов. Это позволяет распределить ошибку максимально равномерно, и её максимальное значение будет минимально возможным.