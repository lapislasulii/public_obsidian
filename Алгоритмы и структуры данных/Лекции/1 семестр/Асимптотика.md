[[Презентация лекции Асимптотика]]
### 1. Введение в асимптотику

**Асимптотическая нотация** (O-нотация) используется для описания временной и пространственной сложности алгоритмов. Она позволяет оценить, как ведет себя алгоритм при значительном увеличении размера входных данных ($N$).

**Основные положения:**

- Оценка алгоритма без учета входных данных не имеет смысла.
- При анализе **константы обычно отбрасываются** (например, $5N$ превращается в $O(N)$), так как асимптотика фокусируется на порядке роста.
- Тем не менее, на практике константа важна: если она слишком велика (например, 15–20), структура данных может быть неэффективной для реальных задач.
- **Иерархия сложности** (от лучших к худшим): $O(1) < O(\log N) < O(N) < O(N \log N) < O(N^2) < O(2^N) < O(N!)$.
- Алгоритмы с факториальной сложностью $O(N!)$ применимы только для очень маленьких массивов (обычно до 12–15 элементов).

### 2. Виды нотаций

Помимо стандартной «O большое», существуют и другие способы оценки:

- **$O(n)$ (Верхняя граница):** Худший случай развития событий.
- **$\Omega(n)$ (Нижняя граница):** Лучший случай.
- **$\Theta(n)$ (Точная граница):** Средний случай или точный порядок роста.
- **$o(n)$ и $\omega(n)$:** Жесткие верхняя и нижняя границы соответственно (функция растет строго медленнее или строго быстрее).

### 3. Сложность операций в структурах данных

В лекции приводится сравнение базовых структур:

|Структура|Доступ по индексу|Вставка в конец (append)|Поиск (find)|Удаление (pop)|
|:--|:--|:--|:--|:--|
|**Vector**|$O(1)$|$O^*(1)$ (аморт.)|$O(N)$|$O^*(1)$ (из конца)|
|**List**|$O(N)$|$O(1)$|$O(N)$|$O(1)$ (из начала/конца)|
|**HashTable**|—|$O^*(1)$ (set)|$O(1)$|$O^*(1)$ (remove)|

_Примечание: $O^_$ обозначает амортизационную сложность (в среднем $O(1)$).*

### 4. Практические примеры оценки

#### Оценка $O(1)$ (Константное время)

К константным операциям относятся:

- Объявление переменных и базовые арифметические действия.
- Доступ к элементу статического или динамического массива (вектора) по индексу.
- Вставка/удаление в связанном списке, если есть указатель на нужный узел.
- Работа с хэш-таблицей (в среднем).

#### Оценка $O(N)$ (Линейное время)

Линейная сложность обычно возникает в циклах, которые проходят по всему массиву один раз. Примером является поиск элемента в не отсортированном списке или векторе.

#### Оценка $O(\log N)$ (Логарифмическое время)

Классический пример — **бинарный поиск**.

- **Суть:** На каждой итерации область поиска сокращается вдвое.
- **Условие:** Массив должен быть отсортирован.
- **Эффективность:** Для массива из 1 000 000 элементов потребуется всего около 20 итераций.

### 5. Задача: Удаление дубликатов

Лектор разбирает оптимизацию алгоритма удаления повторяющихся элементов:

1. **Наивное решение ($O(N^2)$):** Вложенные циклы. Для каждого элемента проверяем его наличие в уже просмотренных с помощью линейного поиска. На 100 000 элементов это может занять около 5 минут.
2. **Оптимизированное решение ($O(N)$):** Использование `hashSet` (или хэш-таблицы) для хранения просмотренных значений. Поиск в хэш-таблице занимает $O(1)$, что сводит общую сложность к линейной.

**Совет по оптимизации:** Если заранее известен размер выходных данных, лучше выделить память под вектор сразу (`createVectorBySize`), чтобы избежать амортизационных затрат на перевыделение памяти в процессе работы.

### 6. Внутренние механизмы: Рехиширование

При переполнении хэш-таблицы (когда количество элементов превышает определенный коэффициент) происходит **рехиширование**:

1. Выделяется новый массив памяти (обычно в 2 раза больше).
2. Все старые значения заново пересчитываются хэш-функцией и вставляются в новую таблицу.
3. Эта операция трудоемка ($O(N)$), но происходит редко, что позволяет сохранить среднюю скорость операций $O(1)$.

**Идеальное хэширование:** теоретическая модель, гарантирующая отсутствие коллизий. В реальности не применяется, так как требует $O(N^2)$ памяти для хранения вложенных таблиц при коллизиях.

---

**Метафора для понимания:** Представьте асимптотику как **выбор транспорта для путешествия**. Если вам нужно пройти 10 метров ($N$ мало), неважно, идете ли вы пешком ($O(N)$) или заводите самолет ($O(N^2)$ с большой константой) — время будет почти одинаковым. Но если путь составляет тысячи километров ($N$ велико), разница между медленным и быстрым алгоритмом превращается в разницу между секундами и годами ожидания.