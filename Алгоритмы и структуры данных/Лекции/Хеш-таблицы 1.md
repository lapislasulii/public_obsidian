[[Презентация лекции Хеш-таблицы]]
## I. Динамические структуры данных и работа с памятью

Лекция началась с обсуждения вопросов, связанных с указателями, константностью и управлением памятью, что является основой для работы с динамическими структурами, такими как связанные списки и хеш-таблицы.

### Основные понятия: Указатели и Память

| Понятие                                                  | Объяснение простым языком (Интуитивное понимание)                                                                                                                                                                   |
| :------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Указатель (Pointer)**                                  | Это **адрес** в памяти, где хранится переменная. Представьте, что это номер квартиры, а не само содержимое квартиры.                                                                                                |
| **Передача по значению** (например, `int var3`)          | В функцию передается **копия** переменной. Любые изменения внутри функции не влияют на исходную переменную вне ее.                                                                                                  |
| **Передача по указателю** (например, `int* var2`)        | В функцию передается **адрес** переменной. Функция может использовать оператор разыменования (`*`) для изменения значения по этому адресу, что изменяет исходную переменную.                                        |
| **Ключевое слово `const`** (например, `const int* var1`) | Используется для того, чтобы **запретить изменение значения** по данному указателю. Это своего рода "страховка от дураков", сигнализирующая другим разработчикам, что сюда лучше не лезть.                          |
| **`malloc(size)`**                                       | Функция, которая выделяет **заданное количество байт** памяти (например, `malloc(100)` выделяет 100 байт). Если используется указатель на `int*`, то 100 байт — это 25 элементов типа `int` (если `int` = 4 байта). |
| **Память в C**                                           | Вся память — это просто **набор байтиков**, и вы, общаясь с компилятором, говорите, как эти байтики нужно считывать (например, как `int*` или `char*`).                                                             |

**Пример работы с памятью и указателями (Вопрос №3)**:

При работе с памятью важно понимать, что переменные (например, `int` и `char`) выделяются в стеке (который обычно идет от старших адресов к младшим). Вы можете **смещаться** по памяти с помощью указателей и **интерпретировать** один и тот же участок памяти как разные типы данных (например, 4 байта как `int` или 1 байт как `char`).

- Если вы приводите указатель к типу `char*` и смещаете его на 1 байт, вы переходите к следующему байту.
- Если вы затем приводите его к типу `int*`, компилятор начинает считывать с этой новой позиции **4 байта** (размер `int`).

### Оптимизация сглаживания массива скользящим окном

Обсуждалась задача сглаживания массива скользящим окном. Исходный подход включал два вложенных цикла, где на каждой итерации внешнего цикла (по массиву) внутренний цикл (по размеру окна $K$) пересчитывал среднее значение. Это приводило к асимптотической сложности **O(N * K)**, которая может быть близка к $O(N^2)$, если размер окна $K$ стремится к размеру массива $N$.

**Что раздражает:** Наличие двух циклов в цикле.

**Решение через Связанный Список:**

Для улучшения производительности предлагается использовать **связанный список**. Вместо пересчета суммы на каждой итерации можно использовать список как динамическое окно:

1. **Добавлять элемент** в конец списка (операция $O(1)$).
2. Как только размер окна достигнут, **извлекать первый элемент** из начала списка (операция $O(1)$). Этот подход позволяет достичь линейной асимптотики **O(N)**, поскольку основные операции (добавление и удаление) выполняются за константное время.

---

## II. Связанный список (GenericList)

Связный список (GenericList) представляет собой базовую динамическую структуру данных.

### Структура списка

Список состоит из двух основных структур:

1. **`Node` (Узел):** Содержит данные (`void *data`) и указатель на следующий узел (`struct Node *next`).
    - _Интуитивное понимание:_ **Узел** — это как вагон поезда: в нем есть твой багаж (данные) и сцепка с следующим вагоном (указатель `next`).
2. **`GenericList` (Сам список):** Содержит указатель на **голову** (`Node *head`) и **размер элемента** (`size_t elem_size`).

**Хранение размера элемента (`elem_size`):**

- Если хранить `elem_size` в структуре `GenericList` (как показано), то **все элементы в списке должны быть одного типа** и размера. Это делает структуру узла меньше, экономя память.
- Если хранить размер элемента в **каждом узле**, то можно хранить элементы разных типов в одном списке (например, `int`, `char`, массив), но это увеличивает объем памяти, занимаемый каждым узлом.

### Псевдокод операций

**Добавление элемента (`appendItem`)**:

1. **Выделить память** под новый узел (`Node`) и под сами данные, которые будут в нем храниться.
2. **Скопировать данные** (`data`) в поле `new_node->data` (используя `memcpy`).
3. Установить указатель на следующий узел (`next`) в `NULL`.
4. Если список пуст, **установить узел первым элементом** (`head`).
5. Иначе **найти последний узел** (тот, у которого `next` равен `NULL`) и сделать новый узел следующим.

**Извлечение элемента по индексу (`popItem`)**:

1. **Проверить** входные данные и сам список (валидация нулей).
2. Найти **предыдущий** элемент (`prev`) относительно удаляемого (по индексу `index - 1`).
3. **Выделить память** под данные и **скопировать** туда данные из текущего узла (чтобы вернуть их из функции).
4. **Поправить указатель:** заменить `prev->next` на `current->next` (или поправить указатель головы, если удаляется первый элемент).
5. **Очистить память** для текущего узла и, что важно, **память для данных** этого узла, если она была выделена.

---

## III. Хеш-Таблицы (Hash Tables)

Хеш-таблицы — это структуры данных, которые позволяют эффективно хранить пары "ключ-значение". Лекция рассматривает, как обойти проблему избыточного использования памяти, присущую простым массивам для поиска (таблицам с прямой адресацией).

### Таблицы с прямой адресацией

Простейший подход для подсчета уникальных элементов:

1. Найти максимальное значение (`max_value`) в исходном массиве.
2. Создать вспомогательный массив (`counter`) размером `max_value`.
3. Использовать каждое число из исходного массива как **индекс** в массиве `counter` и инкрементировать значение по этому индексу.
4. Пройтись по массиву `counter`, чтобы подсчитать, сколько элементов было инкрементировано.

**Ограничение:** Если диапазон ключей **$U = {0, 1, \dots, m-1}$** (например, от 0 до 60 000) слишком велик, создается **разреженный массив**, требующий слишком много памяти.

### Хеш-функция

Для уменьшения требуемой памяти используется **хеш-функция**.

|Понятие|Объяснение простым языком (Интуитивное понимание)|Источники|
|:--|:--|:--|
|**Хеш-функция**|Это "математический компрессор", который принимает большой ключ (например, 60 000) и **сжимает его до маленького, управляемого индекса** (например, от 0 до 99).||
|**Свойство хеш-функции**|Она должна быть **надежной**: при одинаковом входе (ключе) всегда возвращать одинаковый индекс.||
|**Предположение простого равномерного хеширования**|В идеале, для каждого ключа одинаково вероятно, что он попадет в любую из $m$ ячеек хеш-таблицы.||

#### Методы хеширования

1. **Метод деления:** $h(k) = k \bmod m$, где $m$ — размер хеш-таблицы, и желательно, чтобы $m$ было простым числом, далеким от $2^p$.
2. **Метод умножения:** $h(k) = \lfloor m \cdot (k \cdot A \bmod 1) \rfloor$, где $A$ — константа (Кнут предложил $A \approx 0.6180339887\dots$).

### Коллизии и их разрешение

|Понятие|Объяснение простым языком (Интуитивное понимание)|Источники|
|:--|:--|:--|
|**Коллизия**|Когда две **разные** входные переменные (ключа) дают **одинаковый** индекс после применения хеш-функции.||

#### 1. Метод цепочек (Chaining)

Самый простой способ разрешения коллизий: Вместо того, чтобы хранить одно значение в ячейке, каждая ячейка хеш-таблицы (`m` элементов) становится **указателем на связный список** (цепочку). Если происходит коллизия, новый элемент просто добавляется в конец этого списка.

**Ограничение метода цепочек:** Требуется много памяти, так как на каждый элемент, кроме самих данных, нужно выделять память под узел связного списка и указатель `next`.

**Коэффициент заполняемости ($\alpha$)**: $\alpha = n/m$, где $n$ — количество элементов, а $m$ — размер хеш-таблицы. Это **среднее количество элементов, лежащих в одной цепочке**.

- Если $\alpha < 1$: Коллизии маловероятны (при хорошей хеш-функции).
- Если $\alpha > 1$: Коллизии точно будут.

#### 2. Открытая адресация (Open Addressing)

Вместо связного списка элементы хранятся непосредственно в самой хеш-таблице. Если ячейка, которую вернула хеш-функция, занята (произошла коллизия), мы ищем **следующее свободное место** в массиве.

- _Интуитивное понимание:_ Представьте, что вы паркуете машину (элемент) на парковке (хеш-таблице). Если ваше идеальное место занято (коллизия), вы просто едете искать следующее свободное место.

Для поиска следующего свободного места используются различные виды **исследований** (проб):

1. **Линейное исследование:** $h(k, i) = (h'(k) + i) \bmod m$. Мы смещаемся на **один шаг** (i=1, 2, 3...) от исходного индекса, пока не найдем свободную ячейку.
2. **Квадратичное исследование:** $h(k, i) = (h'(k) + c_1i + c_2i^2) \bmod m$. Мы смещаемся на $i^2$ (т.е. на 1, 4, 9, 16...).
3. **Двойное хеширование:** $h(k, i) = (h_1(k) + i \cdot h_2(k)) \bmod m$. Используется вторая хеш-функция $h_2(k)$ для определения шага смещения. Чем более "рандомно" генерируются новые индексы, тем выше вероятность быстро найти свободное место.