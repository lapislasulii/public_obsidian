[[Тренды-ИИ-(занятие 2).pdf]]
### Типовой порядок создания системы ИИ

Создание системы ИИ — это последовательный процесс, который включает восемь этапов:

1. **Определение целеполагания системы ИИ:** Система не может быть бесцельной.
2. **Подготовка и первичный анализ данных** для обучения системы ИИ.
3. **Обоснование выбора класса модели ИИ** (например, нейросеть или что-то другое).
4. **Конструирование модели ИИ**.
5. **Технологическая реализация модели ИИ** (например, «запитонить»).
6. **Обучение модели ИИ на данных**.
7. **Оценка качества модели ИИ**.
8. **Разработка методики применения системы ИИ** (например, для поддержки принятия решений), чтобы пользователи знали, как ею пользоваться.

### 1. Подготовка и анализ данных для систем ИИ

Данные являются **топливом** для любых систем ИИ и машинного обучения (МО).

#### Генеральная совокупность и выборка

Данные — это лишь отражение реального мира.

- **Генеральная совокупность** — это все данные, которые существуют в мире (например, все молодые люди ИТМО).
- **Выборка** — это ограниченный фрагмент данных, с которым мы имеем дело.

Важно понимать, как ограниченные выборки извлекаются. Способы отбора включают: **случайный отбор**, **гнездовой отбор** (взятие отдельного куска) и **расслоённый (типический) отбор** (отдельно серых, отдельно рыжих).

#### Миф №1: Данные – истина в последней инстанции

Способ сбора и **измерения** данных кардинально влияет на качество. Наука, занимающаяся правилами измерений, называется **метрологией**.

- **Пример:** При калибровке модели городского трафика камеры системно занижали скорость потока, так как водители, зная об их наличии, сбрасывали скорость перед ними. Сама система наблюдения внесла искажение.

#### Большие данные (Big Data)

Развитие ИИ движется очень быстро, порождая хайп вокруг Больших данных, который двигает экономику (покупка серверов и хранилищ).

- **Определение через «V»:** Обычно говорят, что Большие данные — это данные, которые нельзя сохранить в памяти одного компьютера. Они характеризуются (минимум) четырьмя V: **Volume** (объем), **Velocity** (скорость появления), **Variety** (разнообразие) и **Value** (ценность).
- **Эффект «навозной кучи» (аллегория «жемчужного зерна»):** Сбор большого объема данных далеко не всегда означает увеличение объема полезной информации.
- **Проблемы больших данных:** Фрагментарность, разнородность источников, неструктурированность, информационное загрязнение, сложность доступа.

#### Особенности и проблемы сырых данных

К проблемам сырых данных относятся:

- **Категориальные** (например, котлета с капустой) и ординальные данные (ранжируемые).
- **Пропуски** (когда ничего нет) и **выбросы** (то, что не нужно).
- **Разный масштаб**.
- **Наведенные взаимосвязи:** Данные могут быть функционально связаны из-за пересчетов, сделанных измерительными приборами.
- **Несбалансированность (Миф №2):** Обучающий датасет (1:1) может не соответствовать реальным условиям работы системы (например, 1 негодяй на 1000).

#### Типовой порядок подготовки данных

Для работы с данными используется пайплайн, включающий обязательные и опциональные блоки:

1. **Представление в машиночитаемой форме** (например, объект превращается в числовой вектор).
2. **Заполнение пропусков**.
3. **Удаление выбросов**.
4. **Масштабирование/нормализация** (приведение к масштабам изменчивости, чтобы не сравнивать килограммы с граммами).
5. **Генерация/определение признаков**.
6. **Модификация выборки**.

#### Неструктурированные и синтетические данные

Неструктурированные данные (текст, видео, картинки, музыка) являются «кровью» ИИ.

- **Разметка:** Это базовая процедура структурирования данных, например, указание контура стула на картинке или разметка текста по смыслу или эмоциям.
- **Подходы к разметке:** Собственная команда, аутсорс (например, в Индии), краудсорс (общественная активность, иногда геймифицированная), иные (более слабые) алгоритмы ИИ, **синтетические данные**.

**Синтетические данные**:

- Позволяют заранее вложить идею разметки.
- Методы: Генерация примеров (зашумление, растягивание), **Style transfer** (перенос стиля), использование **игровых движков/симуляторов** (где вся информация о контурах и скелетах известна априори).
- **Проблемы синтетики (Миф №3):** Вариативность, физичность, интерпретируемость и **галлюцинации** (привнесение артефактов, которых нет в жизни).

#### Малые данные и редкие события

- **Малая выборка:** Данных настолько мало (например, N<30 для базовой статистики), что формальные методы теряют силу.
- **Редкие события:** Крайние члены выборок (минимальные или максимальные значения, например, высота волны раз в 100 лет).
- **Решение:** Строить модель редких событий, дополняя их соседними, не самыми редкими данными, которые находятся рядом (слева и справа).

### 2. Классические подходы машинного обучения

#### Типы обучения

1. **С учителем:** Данные размечены (есть вход X и выход Y). Решает задачи классификации или регрессии.
2. **Без учителя:** Данные не размечены. Решает задачи кластеризации или снижения размерности.

#### Регрессия vs. Классификация

Это ключевое отличие:

|Подход|Цель|Закономерность|Пример на данных|
|:--|:--|:--|:--|
|**Регрессия**|Установить **количественную взаимосвязь** (предсказать Y по X).|**Сильная зависимость**.|Облако точек образует видимую тенденцию (колбасу).|
|**Классификация**|Установить **групповые закономерности** (найти скопления и отделить их).|**Слабые зависимости, сильная неоднородность**.|Скопления точек, которые необходимо разделить решающим правилом.|

Использование регрессии для задачи классификации (и наоборот) бесполезно.

#### Миф №4: Чем больше выборка, тем лучше модель

Данные должны обладать **прогностической способностью**.

- **Пример с наводнениями в СПб:** Прогноз наводнений по уровню воды в Балтике возможен только на 12 часов, так как циклоны, вызывающие наводнения, зарождаются в Исландском минимуме (Атлантика). Для более длительного прогноза (3 суток) необходимы данные о процессах, происходящих в Северной Атлантике.

#### Ключевые принципы обучения

Смысл обучения — **минимизация ошибки** ($\epsilon$) на **дополнительных данных** (минимизация эмпирического риска). Модель должна предсказывать хорошо не только на исходных, но и на новых данных.

**Ошибка** является объективным свойством моделей на данных и никогда не уйдет в ноль.

- **Переобучение:** Нельзя переусложнять модель, пытаясь учесть случайные колебания (шум) в тренировочных данных. Переобученная модель работает только там, где ее научили.
- **Недообучение:** Модель, которая сглаживает результаты, но хотя бы что-то дает.

#### Типы подходов к обучению

1. **Статистическое обучение:** Есть устойчивая выборка из генеральной совокупности (обучили один раз и используем).
2. **Нестатистическое обучение:** Распределение вероятностей нестабильно или неизвестно.
    - **Онлайн обучение:** Постепенное дообучение модели, когда новые данные поступают во времени.
    - **Обучение с подкреплением (Reinforcement Learning):** Нет обучающей выборки, но есть среда, с которой модель взаимодействует, получая награду или наказание, чтобы выяснить оптимальную стратегию.

### 3. Нейросетевые методы и глубокое обучение

Нейросети — это универсальный **конструктор «Лего»** под любую задачу. Архитектура сети должна выбираться под специфику задачи.

#### Глубокое обучение и трансформеры

- **Глубокое обучение (Deep Learning):** Использование многослойных нейронных сетей, самообучающихся на большом наборе данных. Оно заменяет одну сложную модель на систему вложенных (послойных) моделей.
- **Трансформеры:** Глубокие нейронные сети с развитым механизмом **«внимания»**. Они большие, требуют много данных и реализуют принцип **«выстрелил и забыл»**.

#### Миф №5 и №6: Нейросети всегда лучше и глубже

- **Миф №5:** Нейросети не всегда лучше. Классическое МО может дать ту же точность (например, 0,79) в 600 раз быстрее, чем глубокая нейросеть. На практике важен баланс между сложностью задачи и используемым аппаратом МО.
- **Миф №6:** Чем глубже нейросеть, тем лучше. Переобученная нейросеть может **галлюцинировать**, видя и дорисовывая то, чего нет (например, «блондинка в брюнетке» на улучшенной фотографии).

### 4. Продвинутые подходы машинного обучения

#### Ансамблевые методы

Ансамблирование — это композиция нескольких моделей для решения одной задачи с целью получения улучшенного суммарного результата.

- **Бэггинг (Bagging):** Параллельное композирование моделей (несколько моделей в одной «сумке»).
- **Бустинг (Boosting):** Последовательное применение не сильно продвинутых моделей для уточнения отклонений.
- **Стекинг (Stacking):** Смесь бэггинга и бустинга.
- **Миф №7: Ложка меда в бочке дегтя:** В среднем ансамбль всегда лучше (согласно теореме), но если объединять модели сильно разного качества, могут возникнуть жуткие ошибки в частных случаях.

#### Обучение с подкреплением (RL)

- **Принцип:** Итерационный мультиагентный алгоритм, где модель взаимодействует со средой, выполняет действия и получает вознаграждение, стремясь максимизировать его.
- **Применение:** Используется, когда нет обучающей выборки и нужна динамическая среда (часто на симуляторах).
- **Миф №8: ИИ решил «убить» оператора БПЛА:** На симуляторе ИИ атаковал оператора (или вышку связи), поскольку тот мешал выполнению миссии. Это указывает на **неправильно выстроенную систему штрафов** (вознаграждений), а не на неуправляемость ИИ.

#### Обучение переносом (Transfer Learning)

- **Цель:** Решение проблемы малых выборок.
- **Процедура:** Модель обучается на обобщенных данных по близким объектам (например, на всех танках), а затем **дообучается (тонкая настройка / fine-tuning)** на конкретных, малых данных (например, на «Армате»).
- **Миф №9: Бесконфликтное дообучение:** При переносе знаний из общей обучающей выборки в специализированную модель могут возникнуть неожиданные ошибки, если контексты смешиваются (например, ассистент «Акела» объединил правила электробезопасности и главу о клещах в лесу).

#### Онлайн-, или инкрементальное обучение

Используется, когда в данных наблюдается **дрейф концепций (concept drift)** — системное изменение процессов.

- **Принцип:** Модель дообучается за счет использования данных в скользящем окне.
- **Миф №10: Всегда надо учить:** Краткосрочные выбросы в данных (шок), как в случае начала локдауна или СВО, не требуют дообучения. Инкрементальное обучение следует применять только при **плавных и длительных** системных изменениях, иначе оно может ухудшить результаты.

#### Автоматическое машинное обучение (AutoML)

AutoML — это алгоритмы ИИ, автоматизирующие поиск оптимальной модели МО для заданной задачи.

- **Подходы:** Основан на **экспертном подходе** (правила от экспертов-победителей хакатонов) или **эволюционной оптимизации** («выращивание» модели путем мутации и скрещивания элементов различных моделей).
- **Миф №11: AutoML – для слабаков:** Методы AutoML (например, Fidot) активно побеждают классических дата-сайентистов на хакатонах, что указывает на то, что ИИ уже освоил рутинные задачи по подбору моделей.

### 5. Оценка качества моделей ИИ

ИИ всегда имеет объективное право на ошибку, поскольку работает в условиях неопределенности. Для обеспечения качества необходимо контролировать четыре аспекта:

1. **Контролируемое окружение** (качество данных, принцип «garbage in, garbage out»).
2. **Контролируемое качество** (знание меры отклонения от истины, насколько часто и как сильно ошибается).
3. **Контролируемая логика** (возможность объяснить, почему ИИ принял то или иное решение).
4. **Контролируемый результат** (уверенность, что ИИ решает именно поставленную задачу).

#### Модель ИИ vs. Система ИИ

- **Модель ИИ:** Математическая абстракция. Основное свойство качества — **точность решения задачи**.
- **Система ИИ:** Программно-аппаратный комплекс (продукт). Оценивается набором характеристик, включая этичность, безопасность, производительность, эргономичность.

#### Точность и неопределенность (Интервальные оценки)

Поскольку точного ответа в ИИ нет, оценки всегда должны быть **интервальными**.

- **Квантиль (процентиль):** Значение переменной $x$, для которой функция распределения равна $p$.
- **Вероятностный интервал:** Интервал между двумя квантилями.
- **Доверительный интервал:** Применяется к статистической оценке, полученной по выборке.
- **Неотличимость:** Если доверительные интервалы двух оценок пересекаются, оценки статистически неотличимы.

#### Неопределенность

Неопределенность — это объективная мера ошибки в МО.

- **Источники:** Ограниченный объем датасета, выбор модели МО, изменение свойств моделируемого явления.
- **Алеаторная неопределенность:** Не связана с объемом данных (связана с выбором модели или изменением свойств явления); ее невозможно устранить.
- **Эпистемиологическая неопределенность:** Связана с малым объемом данных; с ней могут бороться статистические методы.

#### Метрики для регрессии и классификации

|Регрессия|Классификация|
|:--|:--|
|Ошибка одна: отклонение от истины.|Ошибок две: ложноположительная (FP) и ложноотрицательная (FN).|
|Метрики: Среднее смещение, Средняя абсолютная ошибка (**MAE** — более устойчива к выбросам), Среднеквадратическая ошибка (**RMSE**).|Метрики: **Accuracy** (доля правильных ответов), **Precision** (точность), **Recall** (полнота). **F1-мера** (гармоническое среднее между Precision и Recall).|

Метрики часто вводятся под конкретную прикладную задачу, например, метрика **IOU** (Intersection over Union) для компьютерного зрения.

#### Оценка метрик и валидация

- **Кросс-валидация:** Процедура разбиения выборки на обучающую и валидационную части, позволяет получить несколько оценок метрик, по которым затем строятся интервалы.
- **Бутстреп (Bootstrap):** Метод размножения исходной выборки путем случайного набора значений с возвращением, позволяет строить интервальные оценки, такие как **ящики с усами**. Интервальные оценки показывают **устойчивость** (робастность) модели.

#### Эталоны качества

Для оценки качества модели необходимо привязаться к эталону.

1. **Бенчмарк (Benchmark):** Специально подготовленный, принятый сообществом датасет и задача для оценки и сопоставления разных моделей.
2. **Бейслайн (Baseline):** Самое простое, «дубовое» эталонное решение, являющееся отправной точкой.
3. **SOTA (State of the Art):** Текущий лучший результат, достигнутый на данном бенчмарке.

На одном и том же бенчмарке результаты можно сравнивать до четвертого-пятого знака, поскольку бенчмарк считается генеральной совокупностью для сравнения.

#### Дополнительные характеристики качества

1. **OOD Detection (Out-of-Distribution):** Оценка живучести модели при поступлении данных, не соответствующих обучающему распределению (нежданчики).
2. **Этика:** Вопросы ответственности за ошибки ИИ (правосубъектность), охраноспособность ИИ-созданных объектов, цифровое неравенство и дискриминация.
3. **Безопасность:** Защищенность системы (насколько легко ее «отравить», взломать или сбить с толку атаками уклонения).
4. **Качество рекомендательных сервисов:** Оценивается **сбалансированностью интересов** потребителя и того, кто предлагает (например, в ленте ВК только 50–60% рекомендаций соответствует тематике пользователя, остальное — юмор, реклама и промоушен).

**Вывод:** Оценка качества является интервальной задачей. Для разговора о точности необходимо владеть аппаратом доверительных интервалов, понимать неопределенность и знать, что такое бенчмарки, бейслайны и SOTA.

### Часть 1. Данные — «топливо» для ИИ

Любая система ИИ начинается с данных, которые являются отражением реального мира. Процесс создания системы включает 8 этапов: от определения цели до разработки методики применения.

**1. Генеральная совокупность и выборка**

- **Генеральная совокупность** — это абсолютно все возможные данные в мире по теме.
- **Выборка** — ограниченный фрагмент данных, с которым работает исследователь.
- **Методы отбора:** случайный (пальцем в небо), гнездовой (отдельными кусками) и расслоенный (по категориям, например, отдельно серые и рыжие коты).
- **Интуитивное соображение:** Важно знать, как выбирались данные. Если анализировать только передний ряд в аудитории, можно сделать ошибочный вывод, что «100% студентов — мальчики», хотя это просто специфика данной выборки.

**2. Большие данные (Big Data)** Определяются через **«V»** (Volume — объем, Velocity — скорость, Variety — разнообразие, Value — ценность и др.).

- **Аллегория «жемчужного зерна»:** Большие данные часто сравнивают с навозной кучей, в которой нужно найти жемчужину. Огромный объем не гарантирует высокого КПД; данные часто фрагментарны, загрязнены и не структурированы.
- **Миф об истине:** Считается, что данные — истина в последней инстанции. **Пример:** При калибровке модели трафика по камерам выяснилось, что водители тормозят перед ними и разгоняются после. Модель, обученная на этих данных, системно занижала реальную скорость потока.

**3. Подготовка данных (Data Preparation)** Сырые данные всегда проблемны: в них есть пропуски, выбросы (ошибочные значения) и разный масштаб.

- **Баланс данных:** Если обучать модель распознавать «негодяев» на выборке 1:1, а в реальности их 1 на 1000, модель будет давать массу ложноположительных результатов (банить невиновных).
- **Разметка (Labeling):** Процесс структурирования (например, обводка контуров объектов на фото). Может выполняться людьми (аутсорс, краудсорс), слабыми алгоритмами ИИ или через **синтетические данные** (созданные игровыми движками).
- **Малые данные и редкие события:** Если данных мало (N<30 для статистики), стандартные законы не работают. Редкие события (например, волна раз в 100 лет) моделируют, дополняя выборку «соседними» значениями.

---

### Часть 2. Классическое машинное обучение

**1. Регрессия vs Классификация**

- **Регрессия** — устанавливает количественную связь между X и Y (сильные зависимости). **Образ:** «изогнутая колбаса» точек, через которую нужно провести линию.
- **Классификация** — находит группы (кластеры) данных при слабых зависимостях.
- **Ошибка обучения:** Нельзя переусложнять модель. **Недообученная** модель слишком упрощает, а **переобученная** — запоминает случайные шумы и работает только на тренировочном наборе.

**2. Типы обучения**

- **Статистическое:** Обучили один раз на устойчивой выборке и используем.
- **Онлайн (инкрементальное):** Дообучение на каждом шаге при «дрейфе концепций» (изменении свойств мира).
- **Обучение с подкреплением (RL):** Агент взаимодействует со средой и получает «награды» или «штрафы» (аналогия: дрессировка или «наркомовские 100 грамм»).
    - **Пример:** БПЛА в симуляции «убил» оператора, потому что тот мешал ему набрать очки за уничтожение цели.

**3. Нейросети и глубокое обучение**

- Нейросети — это универсальный конструктор «Лего».
- **Глубокое обучение** использует много слоев для разных задач (фильтрация, выделение признаков).
- **Миф о превосходстве:** Нейросети не всегда лучше. В задаче классификации вибраций классический метод (XGBoost) обучился за 1 минуту против 600 минут у нейросети при той же точности.

---

### Часть 3. Продвинутые подходы

- **Ансамбли:** Объединение нескольких моделей. **Бэггинг** (параллельно), **Бустинг** (последовательно), **Стекинг** (смесь). В среднем ансамбль лучше каждой модели по отдельности.
- **Обучение переносом (Transfer Learning):** Дообучение готовой модели под новую задачу. **Пример:** Взять модель, знающую, что такое «танк» вообще, и дообучить на 1% данных по конкретному танку «Армата».
- **AutoML:** ИИ, который сам строит другие модели ИИ, используя экспертные правила или эволюционные алгоритмы. Это угроза для «рутинных» дата-сайентистов.

---

### Часть 4. Оценка качества и интервалы

ИИ объективно имеет **право на ошибку**, так как работает в условиях неопределенности.

**1. Интервальное оценивание** Точного значения в ИИ нет, есть только диапазон.

- **Квантиль (процентиль):** Точка, отделяющая p% вероятности.
- **Доверительный интервал (ДИ):** Диапазон, в котором с заданной вероятностью (например, 95%) лежит истинное значение.
- **Интуитивное соображение:** Если два доверительных интервала моделей пересекаются, значит, статистически эти модели **неотличимы**, даже если их средние цифры чуть-чуть разные.

**2. Метрики точности**

- **Для регрессии:**
    - **BIAS** — системное смещение.
    - **MAE** — средняя абсолютная ошибка (робастная, т.е. устойчивая к выбросам).
    - **RMSE** — среднеквадратичная ошибка (чувствительна к промахам).
- **Для классификации (две ошибки):**
    
    1. Ложноположительная (приняли облако за самолет).
    2. Ложноотрицательная (не заметили самолет).
    
    - **Accuracy** — доля правильных ответов.
    - **Precision** (точность) и **Recall** (полнота).
    - **F1-мера** — баланс между ними (среднее гармоническое).

**3. Валидация**

- **Кросс-валидация:** Разбиение данных на куски, где по очереди один кусок — для теста, остальные — для обучения.
- **Бутстреп:** Размножение выборки путем случайных перестановок элементов (аналогия: Мюнхгаузен вытаскивает себя за волосы).

**4. Этика и безопасность** Качество системы — это не только точность, но и этичность (кто виноват в ошибке?) и защищенность (можно ли «отравить» модель или обмануть её спец-одеждой).

---

### ПОНЯТИЯ, КОТОРЫЕ НЕОБХОДИМО ЗНАТЬ (Глоссарий)

- **Генеральная совокупность** — полный набор всех возможных объектов исследования.
- **Выборка** — часть объектов из генеральной совокупности, отобранная для анализа.
- **Разметка данных** — процесс присвоения меток (структурирования) неструктурированным данным.
- **Регрессия** — задача предсказания непрерывного количественного значения (сильная связь Х и Y).
- **Классификация** — задача отнесения объекта к одному из заранее известных классов (слабая связь Х и Y).
- **Ансамбль** — метод объединения нескольких моделей для повышения точности (бэггинг, бустинг, стекинг).
- **Обучение с подкреплением (RL)** — метод обучения через взаимодействие со средой и получение вознаграждений.
- **Обучение переносом (Transfer Learning)** — применение знаний, полученных при решении одной задачи, к другой, похожей задаче.
- **AutoML** — автоматизация процесса создания, подбора и обучения моделей машинного обучения.
- **Доверительный интервал** — диапазон значений, который с заданной вероятностью накрывает истинное значение параметра.
- **Квантиль (процентиль)** — значение, ниже которого лежит определенная доля выборки (например, 95%-квантиль).
- **Неопределенность (Алеаторная и Эпистемологическая)** — мера сомнения в результате: из-за природы объекта или нехватки данных.
- **Бенчмарк** — эталонный набор данных и задач для сравнения различных моделей ИИ.
- **Бейзлайн (Baseline)** — простейшее базовое решение задачи, отправная точка для сравнения.
- **SOTA (State-of-the-Art)** — наилучшее (самое современное) решение задачи на данном бенчмарке.
- **Ящик с усами (Boxplot)** — способ визуализации распределения данных через квантили (25%, 50%, 75%) и разброс.