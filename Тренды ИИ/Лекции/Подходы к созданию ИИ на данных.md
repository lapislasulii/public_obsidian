[[Тренды-ИИ-(занятие 2).pdf]]
### Типовой порядок создания системы ИИ

Создание системы ИИ — это последовательный процесс, который включает восемь этапов:

1. **Определение целеполагания системы ИИ:** Система не может быть бесцельной.
2. **Подготовка и первичный анализ данных** для обучения системы ИИ.
3. **Обоснование выбора класса модели ИИ** (например, нейросеть или что-то другое).
4. **Конструирование модели ИИ**.
5. **Технологическая реализация модели ИИ** (например, «запитонить»).
6. **Обучение модели ИИ на данных**.
7. **Оценка качества модели ИИ**.
8. **Разработка методики применения системы ИИ** (например, для поддержки принятия решений), чтобы пользователи знали, как ею пользоваться.

### 1. Подготовка и анализ данных для систем ИИ

Данные являются **топливом** для любых систем ИИ и машинного обучения (МО).

#### Генеральная совокупность и выборка

Данные — это лишь отражение реального мира.

- **Генеральная совокупность** — это все данные, которые существуют в мире (например, все молодые люди ИТМО).
- **Выборка** — это ограниченный фрагмент данных, с которым мы имеем дело.

Важно понимать, как ограниченные выборки извлекаются. Способы отбора включают: **случайный отбор**, **гнездовой отбор** (взятие отдельного куска) и **расслоённый (типический) отбор** (отдельно серых, отдельно рыжих).

#### Миф №1: Данные – истина в последней инстанции

Способ сбора и **измерения** данных кардинально влияет на качество. Наука, занимающаяся правилами измерений, называется **метрологией**.

- **Пример:** При калибровке модели городского трафика камеры системно занижали скорость потока, так как водители, зная об их наличии, сбрасывали скорость перед ними. Сама система наблюдения внесла искажение.

#### Большие данные (Big Data)

Развитие ИИ движется очень быстро, порождая хайп вокруг Больших данных, который двигает экономику (покупка серверов и хранилищ).

- **Определение через «V»:** Обычно говорят, что Большие данные — это данные, которые нельзя сохранить в памяти одного компьютера. Они характеризуются (минимум) четырьмя V: **Volume** (объем), **Velocity** (скорость появления), **Variety** (разнообразие) и **Value** (ценность).
- **Эффект «навозной кучи» (аллегория «жемчужного зерна»):** Сбор большого объема данных далеко не всегда означает увеличение объема полезной информации.
- **Проблемы больших данных:** Фрагментарность, разнородность источников, неструктурированность, информационное загрязнение, сложность доступа.

#### Особенности и проблемы сырых данных

К проблемам сырых данных относятся:

- **Категориальные** (например, котлета с капустой) и ординальные данные (ранжируемые).
- **Пропуски** (когда ничего нет) и **выбросы** (то, что не нужно).
- **Разный масштаб**.
- **Наведенные взаимосвязи:** Данные могут быть функционально связаны из-за пересчетов, сделанных измерительными приборами.
- **Несбалансированность (Миф №2):** Обучающий датасет (1:1) может не соответствовать реальным условиям работы системы (например, 1 негодяй на 1000).

#### Типовой порядок подготовки данных

Для работы с данными используется пайплайн, включающий обязательные и опциональные блоки:

1. **Представление в машиночитаемой форме** (например, объект превращается в числовой вектор).
2. **Заполнение пропусков**.
3. **Удаление выбросов**.
4. **Масштабирование/нормализация** (приведение к масштабам изменчивости, чтобы не сравнивать килограммы с граммами).
5. **Генерация/определение признаков**.
6. **Модификация выборки**.

#### Неструктурированные и синтетические данные

Неструктурированные данные (текст, видео, картинки, музыка) являются «кровью» ИИ.

- **Разметка:** Это базовая процедура структурирования данных, например, указание контура стула на картинке или разметка текста по смыслу или эмоциям.
- **Подходы к разметке:** Собственная команда, аутсорс (например, в Индии), краудсорс (общественная активность, иногда геймифицированная), иные (более слабые) алгоритмы ИИ, **синтетические данные**.

**Синтетические данные**:

- Позволяют заранее вложить идею разметки.
- Методы: Генерация примеров (зашумление, растягивание), **Style transfer** (перенос стиля), использование **игровых движков/симуляторов** (где вся информация о контурах и скелетах известна априори).
- **Проблемы синтетики (Миф №3):** Вариативность, физичность, интерпретируемость и **галлюцинации** (привнесение артефактов, которых нет в жизни).

#### Малые данные и редкие события

- **Малая выборка:** Данных настолько мало (например, N<30 для базовой статистики), что формальные методы теряют силу.
- **Редкие события:** Крайние члены выборок (минимальные или максимальные значения, например, высота волны раз в 100 лет).
- **Решение:** Строить модель редких событий, дополняя их соседними, не самыми редкими данными, которые находятся рядом (слева и справа).

### 2. Классические подходы машинного обучения

#### Типы обучения

1. **С учителем:** Данные размечены (есть вход X и выход Y). Решает задачи классификации или регрессии.
2. **Без учителя:** Данные не размечены. Решает задачи кластеризации или снижения размерности.

#### Регрессия vs. Классификация

Это ключевое отличие:

|Подход|Цель|Закономерность|Пример на данных|
|:--|:--|:--|:--|
|**Регрессия**|Установить **количественную взаимосвязь** (предсказать Y по X).|**Сильная зависимость**.|Облако точек образует видимую тенденцию (колбасу).|
|**Классификация**|Установить **групповые закономерности** (найти скопления и отделить их).|**Слабые зависимости, сильная неоднородность**.|Скопления точек, которые необходимо разделить решающим правилом.|

Использование регрессии для задачи классификации (и наоборот) бесполезно.

#### Миф №4: Чем больше выборка, тем лучше модель

Данные должны обладать **прогностической способностью**.

- **Пример с наводнениями в СПб:** Прогноз наводнений по уровню воды в Балтике возможен только на 12 часов, так как циклоны, вызывающие наводнения, зарождаются в Исландском минимуме (Атлантика). Для более длительного прогноза (3 суток) необходимы данные о процессах, происходящих в Северной Атлантике.

#### Ключевые принципы обучения

Смысл обучения — **минимизация ошибки** ($\epsilon$) на **дополнительных данных** (минимизация эмпирического риска). Модель должна предсказывать хорошо не только на исходных, но и на новых данных.

**Ошибка** является объективным свойством моделей на данных и никогда не уйдет в ноль.

- **Переобучение:** Нельзя переусложнять модель, пытаясь учесть случайные колебания (шум) в тренировочных данных. Переобученная модель работает только там, где ее научили.
- **Недообучение:** Модель, которая сглаживает результаты, но хотя бы что-то дает.

#### Типы подходов к обучению

1. **Статистическое обучение:** Есть устойчивая выборка из генеральной совокупности (обучили один раз и используем).
2. **Нестатистическое обучение:** Распределение вероятностей нестабильно или неизвестно.
    - **Онлайн обучение:** Постепенное дообучение модели, когда новые данные поступают во времени.
    - **Обучение с подкреплением (Reinforcement Learning):** Нет обучающей выборки, но есть среда, с которой модель взаимодействует, получая награду или наказание, чтобы выяснить оптимальную стратегию.

### 3. Нейросетевые методы и глубокое обучение

Нейросети — это универсальный **конструктор «Лего»** под любую задачу. Архитектура сети должна выбираться под специфику задачи.

#### Глубокое обучение и трансформеры

- **Глубокое обучение (Deep Learning):** Использование многослойных нейронных сетей, самообучающихся на большом наборе данных. Оно заменяет одну сложную модель на систему вложенных (послойных) моделей.
- **Трансформеры:** Глубокие нейронные сети с развитым механизмом **«внимания»**. Они большие, требуют много данных и реализуют принцип **«выстрелил и забыл»**.

#### Миф №5 и №6: Нейросети всегда лучше и глубже

- **Миф №5:** Нейросети не всегда лучше. Классическое МО может дать ту же точность (например, 0,79) в 600 раз быстрее, чем глубокая нейросеть. На практике важен баланс между сложностью задачи и используемым аппаратом МО.
- **Миф №6:** Чем глубже нейросеть, тем лучше. Переобученная нейросеть может **галлюцинировать**, видя и дорисовывая то, чего нет (например, «блондинка в брюнетке» на улучшенной фотографии).

### 4. Продвинутые подходы машинного обучения

#### Ансамблевые методы

Ансамблирование — это композиция нескольких моделей для решения одной задачи с целью получения улучшенного суммарного результата.

- **Бэггинг (Bagging):** Параллельное композирование моделей (несколько моделей в одной «сумке»).
- **Бустинг (Boosting):** Последовательное применение не сильно продвинутых моделей для уточнения отклонений.
- **Стекинг (Stacking):** Смесь бэггинга и бустинга.
- **Миф №7: Ложка меда в бочке дегтя:** В среднем ансамбль всегда лучше (согласно теореме), но если объединять модели сильно разного качества, могут возникнуть жуткие ошибки в частных случаях.

#### Обучение с подкреплением (RL)

- **Принцип:** Итерационный мультиагентный алгоритм, где модель взаимодействует со средой, выполняет действия и получает вознаграждение, стремясь максимизировать его.
- **Применение:** Используется, когда нет обучающей выборки и нужна динамическая среда (часто на симуляторах).
- **Миф №8: ИИ решил «убить» оператора БПЛА:** На симуляторе ИИ атаковал оператора (или вышку связи), поскольку тот мешал выполнению миссии. Это указывает на **неправильно выстроенную систему штрафов** (вознаграждений), а не на неуправляемость ИИ.

#### Обучение переносом (Transfer Learning)

- **Цель:** Решение проблемы малых выборок.
- **Процедура:** Модель обучается на обобщенных данных по близким объектам (например, на всех танках), а затем **дообучается (тонкая настройка / fine-tuning)** на конкретных, малых данных (например, на «Армате»).
- **Миф №9: Бесконфликтное дообучение:** При переносе знаний из общей обучающей выборки в специализированную модель могут возникнуть неожиданные ошибки, если контексты смешиваются (например, ассистент «Акела» объединил правила электробезопасности и главу о клещах в лесу).

#### Онлайн-, или инкрементальное обучение

Используется, когда в данных наблюдается **дрейф концепций (concept drift)** — системное изменение процессов.

- **Принцип:** Модель дообучается за счет использования данных в скользящем окне.
- **Миф №10: Всегда надо учить:** Краткосрочные выбросы в данных (шок), как в случае начала локдауна или СВО, не требуют дообучения. Инкрементальное обучение следует применять только при **плавных и длительных** системных изменениях, иначе оно может ухудшить результаты.

#### Автоматическое машинное обучение (AutoML)

AutoML — это алгоритмы ИИ, автоматизирующие поиск оптимальной модели МО для заданной задачи.

- **Подходы:** Основан на **экспертном подходе** (правила от экспертов-победителей хакатонов) или **эволюционной оптимизации** («выращивание» модели путем мутации и скрещивания элементов различных моделей).
- **Миф №11: AutoML – для слабаков:** Методы AutoML (например, Fidot) активно побеждают классических дата-сайентистов на хакатонах, что указывает на то, что ИИ уже освоил рутинные задачи по подбору моделей.

### 5. Оценка качества моделей ИИ

ИИ всегда имеет объективное право на ошибку, поскольку работает в условиях неопределенности. Для обеспечения качества необходимо контролировать четыре аспекта:

1. **Контролируемое окружение** (качество данных, принцип «garbage in, garbage out»).
2. **Контролируемое качество** (знание меры отклонения от истины, насколько часто и как сильно ошибается).
3. **Контролируемая логика** (возможность объяснить, почему ИИ принял то или иное решение).
4. **Контролируемый результат** (уверенность, что ИИ решает именно поставленную задачу).

#### Модель ИИ vs. Система ИИ

- **Модель ИИ:** Математическая абстракция. Основное свойство качества — **точность решения задачи**.
- **Система ИИ:** Программно-аппаратный комплекс (продукт). Оценивается набором характеристик, включая этичность, безопасность, производительность, эргономичность.

#### Точность и неопределенность (Интервальные оценки)

Поскольку точного ответа в ИИ нет, оценки всегда должны быть **интервальными**.

- **Квантиль (процентиль):** Значение переменной $x$, для которой функция распределения равна $p$.
- **Вероятностный интервал:** Интервал между двумя квантилями.
- **Доверительный интервал:** Применяется к статистической оценке, полученной по выборке.
- **Неотличимость:** Если доверительные интервалы двух оценок пересекаются, оценки статистически неотличимы.

#### Неопределенность

Неопределенность — это объективная мера ошибки в МО.

- **Источники:** Ограниченный объем датасета, выбор модели МО, изменение свойств моделируемого явления.
- **Алеаторная неопределенность:** Не связана с объемом данных (связана с выбором модели или изменением свойств явления); ее невозможно устранить.
- **Эпистемиологическая неопределенность:** Связана с малым объемом данных; с ней могут бороться статистические методы.

#### Метрики для регрессии и классификации

|Регрессия|Классификация|
|:--|:--|
|Ошибка одна: отклонение от истины.|Ошибок две: ложноположительная (FP) и ложноотрицательная (FN).|
|Метрики: Среднее смещение, Средняя абсолютная ошибка (**MAE** — более устойчива к выбросам), Среднеквадратическая ошибка (**RMSE**).|Метрики: **Accuracy** (доля правильных ответов), **Precision** (точность), **Recall** (полнота). **F1-мера** (гармоническое среднее между Precision и Recall).|

Метрики часто вводятся под конкретную прикладную задачу, например, метрика **IOU** (Intersection over Union) для компьютерного зрения.

#### Оценка метрик и валидация

- **Кросс-валидация:** Процедура разбиения выборки на обучающую и валидационную части, позволяет получить несколько оценок метрик, по которым затем строятся интервалы.
- **Бутстреп (Bootstrap):** Метод размножения исходной выборки путем случайного набора значений с возвращением, позволяет строить интервальные оценки, такие как **ящики с усами**. Интервальные оценки показывают **устойчивость** (робастность) модели.

#### Эталоны качества

Для оценки качества модели необходимо привязаться к эталону.

1. **Бенчмарк (Benchmark):** Специально подготовленный, принятый сообществом датасет и задача для оценки и сопоставления разных моделей.
2. **Бейслайн (Baseline):** Самое простое, «дубовое» эталонное решение, являющееся отправной точкой.
3. **SOTA (State of the Art):** Текущий лучший результат, достигнутый на данном бенчмарке.

На одном и том же бенчмарке результаты можно сравнивать до четвертого-пятого знака, поскольку бенчмарк считается генеральной совокупностью для сравнения.

#### Дополнительные характеристики качества

1. **OOD Detection (Out-of-Distribution):** Оценка живучести модели при поступлении данных, не соответствующих обучающему распределению (нежданчики).
2. **Этика:** Вопросы ответственности за ошибки ИИ (правосубъектность), охраноспособность ИИ-созданных объектов, цифровое неравенство и дискриминация.
3. **Безопасность:** Защищенность системы (насколько легко ее «отравить», взломать или сбить с толку атаками уклонения).
4. **Качество рекомендательных сервисов:** Оценивается **сбалансированностью интересов** потребителя и того, кто предлагает (например, в ленте ВК только 50–60% рекомендаций соответствует тематике пользователя, остальное — юмор, реклама и промоушен).

**Вывод:** Оценка качества является интервальной задачей. Для разговора о точности необходимо владеть аппаратом доверительных интервалов, понимать неопределенность и знать, что такое бенчмарки, бейслайны и SOTA.